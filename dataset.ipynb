{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a48ba5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !molecule_generation preprocess INPUT_DIR OUTPUT_DIR TRACE_DIR --generation-order=canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5bfe46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/data/ongh0068/l1000/moler_reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b6b2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 08:29:38.848042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "with gzip.open('/data/ongh0068/l1000/trace_playground/metadata.pkl.gz', 'rb') as f:\n",
    "     metadata= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d14815a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "with gzip.open('/data/ongh0068/l1000/trace_playground/train_0/train_0.pkl.gz', 'rb') as f:\n",
    "     train= pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722bd97b",
   "metadata": {},
   "source": [
    "# Misc TODOs\n",
    "\n",
    "1. Add a motif embedding layer to the GNN => need to look into whether there are specific gnn layers for this\n",
    "2. Dataset => validate if it is correct\n",
    "3. Implement function for storing Data objects in the Pytorch geometric dataset\n",
    "4. Implement all the helper function for the pytorch geometric dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3b2f61",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "The original dataset uses a function to randomly decide whether to include or exclude a particular partial graph from the batch. Instead of that, we try to simply save all Data objects a separate .pt files => at training time, we list all the file paths and then sample from the file paths uniformly \n",
    "\n",
    "- Downsides => will occupy more memory: potential optimisations (TODOs) would be to save as compressed file and only decompress at training time.\n",
    "- Upside => less preprocessing time at training time\n",
    "\n",
    "\n",
    "There will be 1 dataset object for each of the train/validation/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e593694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de30442",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for step in train[0]:\n",
    "#     print(step)\n",
    "    count += 1\n",
    "    if count == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18086a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset\n",
    "import os\n",
    "from molecule_generation.chem.motif_utils import get_motif_type_to_node_type_index_map\n",
    "\n",
    "\n",
    "def get_motif_type_to_node_type_index_map(\n",
    "    motif_vocabulary, num_atom_types\n",
    "):\n",
    "    \"\"\"Helper to construct a mapping from motif type to shifted node type.\"\"\"\n",
    "\n",
    "    return {\n",
    "        motif: num_atom_types + motif_type\n",
    "        for motif, motif_type in motif_vocabulary.vocabulary.items()\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "class MolerDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        root, \n",
    "        raw_moler_trace_dataset_parent_folder, # absolute path \n",
    "        output_pyg_trace_dataset_parent_folder, # absolute path\n",
    "        split = 'train',\n",
    "        transform=None, \n",
    "        pre_transform=None, \n",
    "    ):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self._transform = transform \n",
    "        self._pre_transform = pre_transform\n",
    "        self._raw_moler_trace_dataset_parent_folder = raw_moler_trace_dataset_parent_folder\n",
    "        self._output_pyg_trace_dataset_parent_folder = output_pyg_trace_dataset_parent_folder\n",
    "        self._split = split\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\"\n",
    "        Raw generation trace files output from the preprocess function of the cli. These are zipped pickle\n",
    "        files. This is the actual file name without the parent folder.\n",
    "        \"\"\"\n",
    "        raw_file_paths_folder = os.path.join(self._raw_moler_trace_dataset_parent_folder, self._split)\n",
    "        assert os.path.exist(raw_file_paths_folder), f'{raw_file_paths_folder} does not exist.'\n",
    "        raw_generation_trace_files = [file_path for file_path in os.listdir(raw_file_paths_folder)]\n",
    "        return raw_generation_trace_files\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\"Processed generation trace objects that are stored as .pt files\"\"\"\n",
    "        processed_file_paths_folder = os.path.join(self._output_pyg_trace_dataset_parent_folder, self._split)\n",
    "        assert os.path.exist(raw_file_paths_folder), f'{raw_file_paths_folder} does not exist.'\n",
    "        processed_generation_trace_files = [os.path.join(file)  for file in os.listdir(processed_file_paths_folder)]\n",
    "        return processed_generation_trace_files\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names_size(self):\n",
    "        return len(self.processed_file_names)\n",
    "    \n",
    "    @property \n",
    "    def metadata(self):\n",
    "        return self._metadata\n",
    "\n",
    "    def node_types_to_multi_hot(self, node_types):\n",
    "        \"\"\"Convert between string representation to multi hot encoding of correct node types.\n",
    "\n",
    "        Note: implemented here for backwards compatibility only.\n",
    "        \"\"\"\n",
    "        return np.zeros(shape=(self.num_node_types,), dtype=np.float32)\n",
    "\n",
    "    def node_type_to_index(self, node_type):\n",
    "        motif_node_type_index = self._motif_to_node_type_index.get(node_type)\n",
    "\n",
    "        if motif_node_type_index is not None:\n",
    "            return motif_node_type_index\n",
    "        else:\n",
    "            return self._atom_type_featuriser.type_name_to_index(node_type)\n",
    "    \n",
    "    @property\n",
    "    def num_node_types(self):\n",
    "        return len(self.node_type_index_to_string)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def load_metadata(self, metadata_path):\n",
    "        metadata_file_path = os.path.join(self._raw_moler_trace_dataset_parent_folder, 'metadata.pkl.gz')\n",
    "        \n",
    "        with gzip.open(metadata_file_path, 'rb') as f:\n",
    "             self._metadata = pickle.load(f)\n",
    "        \n",
    "        self._atom_type_featuriser = next(\n",
    "            featuriser\n",
    "            for featuriser in self._metadata[\"feature_extractors\"]\n",
    "            if featuriser.name == \"AtomType\"\n",
    "        )\n",
    "        \n",
    "        self._node_type_index_to_string = self._atom_type_featuriser.index_to_atom_type_map.copy()\n",
    "        self._motif_vocabulary = self.metadata.get(\"motif_vocabulary\")\n",
    "\n",
    "        if self._motif_vocabulary is not None:\n",
    "            self._motif_to_node_type_index = get_motif_type_to_node_type_index_map(\n",
    "                motif_vocabulary=self._motif_vocabulary,\n",
    "                num_atom_types=len(self._node_type_index_to_string),\n",
    "            )\n",
    "\n",
    "            for motif, node_type in self._motif_to_node_type_index.items():\n",
    "                self._node_type_index_to_string[node_type] = motif\n",
    "        else:\n",
    "            self._motif_to_node_type_index = {}\n",
    "        \n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"Convert raw generation traces into individual .pt files for each of the trace steps.\"\"\"\n",
    "        # only call process if it was not called before\n",
    "        if self.processed_file_names_size > 0:\n",
    "            pass\n",
    "        else:\n",
    "            for pkl_file_path in self.raw_file_names:\n",
    "                generation_steps = self._convert_data_shard_to_list_of_trace_steps(pkl_file_path)\n",
    "                for molecule_idx, molecule_gen_steps in generation_steps:\n",
    "                    for step_idx, step in enumerate(molecule_gen_steps):\n",
    "                        file_name = f'{pkl_file_path}_mol_{molecule_idx}_step_{step_idx}.pt'\n",
    "                        file_path = os.path.join(self._output_pyg_trace_dataset_parent_folder, file_name)\n",
    "                        torch.save(step, file_path)\n",
    "\n",
    "    def _convert_data_shard_to_list_of_trace_steps(self, pkl_file_path):\n",
    "        # TODO: multiprocessing to speed this up\n",
    "        generation_steps = []\n",
    "        \n",
    "        with gzip.open(pkl_file_path, 'rb') as f:\n",
    "            molecules = pickle.load(f)\n",
    "            for molecule_idx, molecule in enumerate(molecules): \n",
    "                generation_steps.extend([i, self._extract_generation_steps(molecule)])\n",
    "                \n",
    "        return generation_steps\n",
    "            \n",
    "    def _extract_generation_steps(self, molecule):\n",
    "        for gen_step in molecule:\n",
    "            x = gen_step.partial_node_features\n",
    "            node_categorical_features = gen_step.node_categorical_features\n",
    "        \n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31853d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbdcd0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('/data/ongh0068/l1000/trace_playground/metadata.pkl.gz', 'rb') as f:\n",
    "     metadata= pickle.load(f)\n",
    "\n",
    "atom_type_featuriser = next(\n",
    "    featuriser\n",
    "    for featuriser in metadata[\"feature_extractors\"]\n",
    "    if featuriser.name == \"AtomType\"\n",
    ")\n",
    "\n",
    "node_type_index_to_string = atom_type_featuriser.index_to_atom_type_map.copy()\n",
    "motif_vocabulary = metadata.get(\"motif_vocabulary\")\n",
    "\n",
    "if motif_vocabulary is not None:\n",
    "    motif_to_node_type_index = get_motif_type_to_node_type_index_map(\n",
    "        motif_vocabulary=motif_vocabulary,\n",
    "        num_atom_types=len(node_type_index_to_string),\n",
    "    )\n",
    "\n",
    "    for motif, node_type in motif_to_node_type_index.items():\n",
    "        node_type_index_to_string[node_type] = motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd2a550c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'UNK',\n",
       " 1: 'C',\n",
       " 2: 'O',\n",
       " 3: 'N',\n",
       " 4: 'S',\n",
       " 5: 'Cl',\n",
       " 6: 'F',\n",
       " 7: 'N+',\n",
       " 8: 'O-',\n",
       " 9: 'B',\n",
       " 10: 'Br',\n",
       " 11: 'C1=CC=CC=C1',\n",
       " 12: 'C1CCNCC1',\n",
       " 13: 'C1=CC=NC=C1',\n",
       " 14: 'NC=O',\n",
       " 15: 'C1CNCCN1',\n",
       " 16: 'C1CCNC1',\n",
       " 17: 'O=[N+][O-]',\n",
       " 18: 'C1CC1',\n",
       " 19: 'C1COCCN1',\n",
       " 20: 'O=CO',\n",
       " 21: 'N=CO',\n",
       " 22: 'C1=CNN=C1',\n",
       " 23: 'FC(F)F',\n",
       " 24: 'CC=O',\n",
       " 25: 'C1CCOCC1',\n",
       " 26: 'C1=CC=C2C=CC=CC2=C1',\n",
       " 27: 'COC=O',\n",
       " 28: 'CCO',\n",
       " 29: 'C=CC',\n",
       " 30: 'C1=CSC=N1',\n",
       " 31: 'C1=CSC=C1',\n",
       " 32: 'C1=CON=C1',\n",
       " 33: 'C1=CC=C2NC=CC2=C1',\n",
       " 34: 'OC(F)F',\n",
       " 35: 'O=CNO',\n",
       " 36: 'CNC=O',\n",
       " 37: 'CCNC(=O)OC',\n",
       " 38: 'CCCO',\n",
       " 39: 'CCC(N)=O',\n",
       " 40: 'CCC(=O)O',\n",
       " 41: 'CC(N)=O',\n",
       " 42: 'CC(C)C',\n",
       " 43: 'C1CCOC1',\n",
       " 44: 'C1CCCCC1',\n",
       " 45: 'C1=NC=C2CCCCC2=N1',\n",
       " 46: 'C1=COC=C1',\n",
       " 47: 'C1=CNC=C1',\n",
       " 48: 'C1=CN=CN=C1',\n",
       " 49: 'C1=CN=C2C=CC=CC2=C1',\n",
       " 50: 'C1=CN2N=CC=C2N=C1',\n",
       " 51: 'C1=CC=C2OC=CCC2=C1',\n",
       " 52: 'C1=CC=C2N=CC=CC2=C1',\n",
       " 53: 'C1=CC2=C(CCC2)S1',\n",
       " 54: 'O=S=O',\n",
       " 55: 'O=CNCCO',\n",
       " 56: 'O=CNCCCCCNC=O',\n",
       " 57: 'O=CNCCC(=O)O',\n",
       " 58: 'O=CCCO',\n",
       " 59: 'O=C(O)CS',\n",
       " 60: 'N[SH](=O)=O',\n",
       " 61: 'NNC=O',\n",
       " 62: 'NCCO',\n",
       " 63: 'NCCCC(N)=O',\n",
       " 64: 'NC(N)=O',\n",
       " 65: 'ClC(Cl)Cl',\n",
       " 66: 'CSCCC(N)C(=O)O',\n",
       " 67: 'COS(=O)(=O)CCC(N)=O',\n",
       " 68: 'CNCCOC',\n",
       " 69: 'CNC(C)=O',\n",
       " 70: 'CNC(=O)CS',\n",
       " 71: 'CNC(=O)C(CC(=O)NC(CC(C)C)B(O)O)NC(=O)OC(C)(C)C',\n",
       " 72: 'CNC',\n",
       " 73: 'CN=CO',\n",
       " 74: 'CN(C)C(N)=O',\n",
       " 75: 'CCOCC',\n",
       " 76: 'CCOC=O',\n",
       " 77: 'CCOC',\n",
       " 78: 'CCNC(C)=O',\n",
       " 79: 'CCNC(=O)CC',\n",
       " 80: 'CCN(C)C',\n",
       " 81: 'CCN',\n",
       " 82: 'CCCNC(=O)NCCCCCCCCCCCCCCCC(=O)O',\n",
       " 83: 'CCCNC(=O)CCCNC=O',\n",
       " 84: 'CCCCNCC',\n",
       " 85: 'CCCCCO',\n",
       " 86: 'CCCCCCCO',\n",
       " 87: 'CCCCCCC=CC(C)=O',\n",
       " 88: 'CCCCCC(C)C',\n",
       " 89: 'CCCCCC(=O)OC',\n",
       " 90: 'CCCCC',\n",
       " 91: 'CCCC(C)N',\n",
       " 92: 'CCCC(=O)NCCC#N',\n",
       " 93: 'CCCC',\n",
       " 94: 'CCC(COC(=O)C(C)(C)C)NC(=S)NC',\n",
       " 95: 'CCC(C)C(NC=O)C(N)=O',\n",
       " 96: 'CCC(C)C(NC(=O)C(N)CO)C(=O)NC(C)C(N)=O',\n",
       " 97: 'CCC',\n",
       " 98: 'CC=NNC=S',\n",
       " 99: 'CC(NC=O)C(N)=O',\n",
       " 100: 'CC(NC=O)C(=O)CCC=O',\n",
       " 101: 'CC(N)C(=O)NC(C=O)C(C)C',\n",
       " 102: 'CC(C)SCC(O)C(C)NC(=O)C(C)NC(=O)C(C)NC(=O)OC(C)(C)C',\n",
       " 103: 'CC(C)O',\n",
       " 104: 'CC(C)C(N)=O',\n",
       " 105: 'CC(=O)OCC(N)=O',\n",
       " 106: 'CC(=O)O',\n",
       " 107: 'CC(=O)NCC(=O)O',\n",
       " 108: 'CC(=O)N(C)C',\n",
       " 109: 'CC#N',\n",
       " 110: 'C=NO',\n",
       " 111: 'C=NNC=O',\n",
       " 112: 'C=NNC(=O)NCCCC',\n",
       " 113: 'C=CCOC(C)=O',\n",
       " 114: 'C=CC(=O)C=C(O)C=C',\n",
       " 115: 'C1OC2CNC1C2',\n",
       " 116: 'C1NCC12COC2',\n",
       " 117: 'C1NC2C3C4CC5C3C1C1C5C4C21',\n",
       " 118: 'C1CNCNC1',\n",
       " 119: 'C1CNCCNC1',\n",
       " 120: 'C1CNC1',\n",
       " 121: 'C1CCC2CCCC2C1',\n",
       " 122: 'C1CCC2C(C1)CCC1C3CCCC3CCC21',\n",
       " 123: 'C1CCC2=C(C1)CC1=C(CCCC1)O2',\n",
       " 124: 'C1CC2OCCC2CN1',\n",
       " 125: 'C1CC2CCC1C2',\n",
       " 126: 'C1C2CC3CC1CC(C2)C3',\n",
       " 127: 'C1=NO[N+]=C1',\n",
       " 128: 'C1=NNN=N1',\n",
       " 129: 'C1=NNC2=C1CCCC2',\n",
       " 130: 'C1=NN=NN1',\n",
       " 131: 'C1=NN=C2SC=NN12',\n",
       " 132: 'C1=NN2CCCNC2=C1',\n",
       " 133: 'C1=NC=NO1',\n",
       " 134: 'C1=NC=NN1',\n",
       " 135: 'C1=NC=NC=N1',\n",
       " 136: 'C1=NC=NC2=C1N=CN2',\n",
       " 137: 'C1=NC2=C(CNCN2)N1',\n",
       " 138: 'C1=CSCN1'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_type_index_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8564bb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_997897/2528646342.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  molecule_gen_steps[i][k] = torch.tensor(molecule_gen_steps[i][k])\n"
     ]
    }
   ],
   "source": [
    "def node_types_to_indices(node_types):\n",
    "    node_type_to_index\n",
    "    \"\"\"Convert list of string representations into list of integer indices.\"\"\"\n",
    "    return [node_type_to_index(node_type) for node_type in node_types]\n",
    "\n",
    "def node_types_to_multi_hot(node_types):\n",
    "    \"\"\"Convert between string representation to multi hot encoding of correct node types.\n",
    "\n",
    "    Note: implemented here for backwards compatibility only.\n",
    "    \"\"\"\n",
    "    num_node_types = len(node_type_index_to_string)\n",
    "    return np.zeros(shape=(num_node_types,), dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "train_sample = train[0]\n",
    "\n",
    "molecule_gen_steps = []\n",
    "for gen_step in train_sample:\n",
    "    gen_step_features = {}\n",
    "    gen_step_features['x'] = gen_step.partial_node_features\n",
    "    gen_step_features['focus_node'] = gen_step.focus_node\n",
    "    \n",
    "    # have an edge type attribute to tell apart each of the 3 bond types\n",
    "    edge_indexes = []\n",
    "    edge_types= []\n",
    "    for i, adj_list in enumerate(gen_step.partial_adjacency_lists):\n",
    "        if len(adj_list) != 0:\n",
    "            edge_index = torch.tensor(adj_list).T\n",
    "            edge_indexes += [edge_index]\n",
    "            edge_types += [i]*len(adj_list)\n",
    "    gen_step_features['edge_index'] = torch.cat(edge_indexes, 1)\n",
    "    gen_step_features['edge_type'] = torch.tensor(edge_types)\n",
    "    gen_step_features['correct_edge_choices'] = gen_step.correct_edge_choices\n",
    "    num_correct_edge_choices = np.sum(gen_step.correct_edge_choices)\n",
    "    gen_step_features['num_correct_edge_choices'] = num_correct_edge_choices\n",
    "    gen_step_features['stop_node_label'] = int(num_correct_edge_choices == 0)\n",
    "    gen_step_features['valid_edge_choices'] = gen_step.valid_edge_choices\n",
    "    gen_step_features[\"correct_edge_types\"] = gen_step.correct_edge_types\n",
    "    gen_step_features[\"partial_node_categorical_features\"] = gen_step.partial_node_categorical_features\n",
    "    if gen_step.correct_attachment_point_choice is not None:\n",
    "        gen_step_features[\"correct_attachment_point_choice\"] = list(gen_step.valid_attachment_point_choices).index(gen_step.correct_attachment_point_choice)\n",
    "    else:\n",
    "        gen_step_features[\"correct_attachment_point_choice\"] = []\n",
    "    gen_step_features[\"valid_attachment_point_choices\"] = gen_step.valid_attachment_point_choices\n",
    "    \n",
    "    # And finally, the correct node type choices. Here, we have an empty list of\n",
    "    # correct choices for all steps where we didn't choose a node, so we skip that:\n",
    "    if gen_step.correct_node_type_choices is not None:\n",
    "        gen_step_features[\"correct_node_type_choices\"] = node_types_to_multi_hot(gen_step.correct_node_type_choices)\n",
    "    else:\n",
    "        gen_step_features[\"correct_node_type_choices\"] = []\n",
    "    gen_step_features['correct_first_node_type_choices'] = node_types_to_multi_hot(train_sample.correct_first_node_type_choices)\n",
    "\n",
    "    molecule_gen_steps += [gen_step_features]\n",
    "for i in range(len(molecule_gen_steps)):\n",
    "    for k,v in molecule_gen_steps[i].items():\n",
    "        molecule_gen_steps[i][k] = torch.tensor(molecule_gen_steps[i][k])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "79e28771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "pyg_data = []\n",
    "for step in molecule_gen_steps:\n",
    "    pyg_data.append(Data(**step))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "24b7beba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "loader = DataLoader(pyg_data, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "48567304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([0])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_data[9].correct_node_type_choices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4136dcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4, 32], edge_index=[2, 6], focus_node=0, edge_type=[6], correct_edge_choices=[0], num_correct_edge_choices=0.0, stop_node_label=1, valid_edge_choices=[0, 2], correct_edge_types=[0, 3], partial_node_categorical_features=[4], correct_attachment_point_choice=[0], valid_attachment_point_choices=[0], correct_node_type_choices=[139], correct_first_node_type_choices=[139])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "15cb21b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   4,   9,  14,  20,  26,  33,  40,  48,  56,  65,  74,  84,  94,\n",
       "        104, 115, 126])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c096cab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[126, 32], edge_index=[2, 212], focus_node=[16], edge_type=[212], correct_edge_choices=[53], num_correct_edge_choices=[16], stop_node_label=[16], valid_edge_choices=[53, 2], correct_edge_types=[9, 3], partial_node_categorical_features=[126], correct_attachment_point_choice=[0], valid_attachment_point_choices=[0], correct_node_type_choices=[1112], correct_first_node_type_choices=[2224], batch=[126], ptr=[17])\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c8d9a75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 1],\n",
       "       [2, 2],\n",
       "       [3, 3],\n",
       "       [4, 4]], dtype=int32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(np.arange(5, dtype=np.int32), 2).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36219c72",
   "metadata": {},
   "source": [
    "# Issues to resolve\n",
    "\n",
    "Here, for a batch size of 16, there are 4 nodes in the first sample in the batch and 126 nodes in total as seen from x. the `ptr` attribute tells us where each new graph starts in the batch.\n",
    "\n",
    "\n",
    "Add self loops\n",
    "\n",
    "There is something wrong with the multihot encoding: none of the node types are of value 1\n",
    "1. edge_index: how do we tell which belongs to which graph? Does it matter?\n",
    "2. focus node: NI\n",
    "3. edge type: same as edge index, how to tell?\n",
    "4. correct_edge_choices: need to put a -1 for those samples without any?\n",
    "5. num_correct_edge_choices: NI, for each of the 16 samples => can be used to infer which graphs to use for training the decoder mlps\n",
    "6. stop_node_label: NI\n",
    "7. valid_edge_choices: need to put -1 for samples without any\n",
    "8. correct_edge_types: need to put -1 for samples without any \n",
    "9. partial_node_categorical_features: NI\n",
    "10. correct_attachment_point_choice: need to put -1 for samples without any\n",
    "11. valid_attachment_point_choices: need to put -1 for samples without any\n",
    "12. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9bbc25be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.correct_node_type_choices.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5df9d71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 56,  65,  74,  84,  94, 104, 115, 126])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.ptr[batch.ptr > 50] # use this kind of numpy like indexing to get \n",
    "# the values we want\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "875289e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C1=CC=CC=C1': 0,\n",
       " 'C1CCNCC1': 1,\n",
       " 'C1=CC=NC=C1': 2,\n",
       " 'NC=O': 3,\n",
       " 'C1CNCCN1': 4,\n",
       " 'C1CCNC1': 5,\n",
       " 'O=[N+][O-]': 6,\n",
       " 'C1CC1': 7,\n",
       " 'C1COCCN1': 8,\n",
       " 'O=CO': 9,\n",
       " 'N=CO': 10,\n",
       " 'C1=CNN=C1': 11,\n",
       " 'FC(F)F': 12,\n",
       " 'CC=O': 13,\n",
       " 'C1CCOCC1': 14,\n",
       " 'C1=CC=C2C=CC=CC2=C1': 15,\n",
       " 'COC=O': 16,\n",
       " 'CCO': 17,\n",
       " 'C=CC': 18,\n",
       " 'C1=CSC=N1': 19,\n",
       " 'C1=CSC=C1': 20,\n",
       " 'C1=CON=C1': 21,\n",
       " 'C1=CC=C2NC=CC2=C1': 22,\n",
       " 'OC(F)F': 23,\n",
       " 'O=CNO': 24,\n",
       " 'CNC=O': 25,\n",
       " 'CCNC(=O)OC': 26,\n",
       " 'CCCO': 27,\n",
       " 'CCC(N)=O': 28,\n",
       " 'CCC(=O)O': 29,\n",
       " 'CC(N)=O': 30,\n",
       " 'CC(C)C': 31,\n",
       " 'C1CCOC1': 32,\n",
       " 'C1CCCCC1': 33,\n",
       " 'C1=NC=C2CCCCC2=N1': 34,\n",
       " 'C1=COC=C1': 35,\n",
       " 'C1=CNC=C1': 36,\n",
       " 'C1=CN=CN=C1': 37,\n",
       " 'C1=CN=C2C=CC=CC2=C1': 38,\n",
       " 'C1=CN2N=CC=C2N=C1': 39,\n",
       " 'C1=CC=C2OC=CCC2=C1': 40,\n",
       " 'C1=CC=C2N=CC=CC2=C1': 41,\n",
       " 'C1=CC2=C(CCC2)S1': 42,\n",
       " 'O=S=O': 43,\n",
       " 'O=CNCCO': 44,\n",
       " 'O=CNCCCCCNC=O': 45,\n",
       " 'O=CNCCC(=O)O': 46,\n",
       " 'O=CCCO': 47,\n",
       " 'O=C(O)CS': 48,\n",
       " 'N[SH](=O)=O': 49,\n",
       " 'NNC=O': 50,\n",
       " 'NCCO': 51,\n",
       " 'NCCCC(N)=O': 52,\n",
       " 'NC(N)=O': 53,\n",
       " 'ClC(Cl)Cl': 54,\n",
       " 'CSCCC(N)C(=O)O': 55,\n",
       " 'COS(=O)(=O)CCC(N)=O': 56,\n",
       " 'CNCCOC': 57,\n",
       " 'CNC(C)=O': 58,\n",
       " 'CNC(=O)CS': 59,\n",
       " 'CNC(=O)C(CC(=O)NC(CC(C)C)B(O)O)NC(=O)OC(C)(C)C': 60,\n",
       " 'CNC': 61,\n",
       " 'CN=CO': 62,\n",
       " 'CN(C)C(N)=O': 63,\n",
       " 'CCOCC': 64,\n",
       " 'CCOC=O': 65,\n",
       " 'CCOC': 66,\n",
       " 'CCNC(C)=O': 67,\n",
       " 'CCNC(=O)CC': 68,\n",
       " 'CCN(C)C': 69,\n",
       " 'CCN': 70,\n",
       " 'CCCNC(=O)NCCCCCCCCCCCCCCCC(=O)O': 71,\n",
       " 'CCCNC(=O)CCCNC=O': 72,\n",
       " 'CCCCNCC': 73,\n",
       " 'CCCCCO': 74,\n",
       " 'CCCCCCCO': 75,\n",
       " 'CCCCCCC=CC(C)=O': 76,\n",
       " 'CCCCCC(C)C': 77,\n",
       " 'CCCCCC(=O)OC': 78,\n",
       " 'CCCCC': 79,\n",
       " 'CCCC(C)N': 80,\n",
       " 'CCCC(=O)NCCC#N': 81,\n",
       " 'CCCC': 82,\n",
       " 'CCC(COC(=O)C(C)(C)C)NC(=S)NC': 83,\n",
       " 'CCC(C)C(NC=O)C(N)=O': 84,\n",
       " 'CCC(C)C(NC(=O)C(N)CO)C(=O)NC(C)C(N)=O': 85,\n",
       " 'CCC': 86,\n",
       " 'CC=NNC=S': 87,\n",
       " 'CC(NC=O)C(N)=O': 88,\n",
       " 'CC(NC=O)C(=O)CCC=O': 89,\n",
       " 'CC(N)C(=O)NC(C=O)C(C)C': 90,\n",
       " 'CC(C)SCC(O)C(C)NC(=O)C(C)NC(=O)C(C)NC(=O)OC(C)(C)C': 91,\n",
       " 'CC(C)O': 92,\n",
       " 'CC(C)C(N)=O': 93,\n",
       " 'CC(=O)OCC(N)=O': 94,\n",
       " 'CC(=O)O': 95,\n",
       " 'CC(=O)NCC(=O)O': 96,\n",
       " 'CC(=O)N(C)C': 97,\n",
       " 'CC#N': 98,\n",
       " 'C=NO': 99,\n",
       " 'C=NNC=O': 100,\n",
       " 'C=NNC(=O)NCCCC': 101,\n",
       " 'C=CCOC(C)=O': 102,\n",
       " 'C=CC(=O)C=C(O)C=C': 103,\n",
       " 'C1OC2CNC1C2': 104,\n",
       " 'C1NCC12COC2': 105,\n",
       " 'C1NC2C3C4CC5C3C1C1C5C4C21': 106,\n",
       " 'C1CNCNC1': 107,\n",
       " 'C1CNCCNC1': 108,\n",
       " 'C1CNC1': 109,\n",
       " 'C1CCC2CCCC2C1': 110,\n",
       " 'C1CCC2C(C1)CCC1C3CCCC3CCC21': 111,\n",
       " 'C1CCC2=C(C1)CC1=C(CCCC1)O2': 112,\n",
       " 'C1CC2OCCC2CN1': 113,\n",
       " 'C1CC2CCC1C2': 114,\n",
       " 'C1C2CC3CC1CC(C2)C3': 115,\n",
       " 'C1=NO[N+]=C1': 116,\n",
       " 'C1=NNN=N1': 117,\n",
       " 'C1=NNC2=C1CCCC2': 118,\n",
       " 'C1=NN=NN1': 119,\n",
       " 'C1=NN=C2SC=NN12': 120,\n",
       " 'C1=NN2CCCNC2=C1': 121,\n",
       " 'C1=NC=NO1': 122,\n",
       " 'C1=NC=NN1': 123,\n",
       " 'C1=NC=NC=N1': 124,\n",
       " 'C1=NC=NC2=C1N=CN2': 125,\n",
       " 'C1=NC2=C(CNCN2)N1': 126,\n",
       " 'C1=CSCN1': 127}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['motif_vocabulary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6be33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def safe_concat(data, dtype, shape_suffix = ()):\n",
    "    if len(data) > 0:\n",
    "        return np.concatenate(data).astype(dtype)\n",
    "    else:\n",
    "        return np.zeros(shape=(0,) + shape_suffix, dtype=dtype)\n",
    "\n",
    "\n",
    "def safe_make_array(data, dtype, shape_suffix= ()):\n",
    "    if len(data) > 0:\n",
    "        return np.array(data, dtype=dtype)\n",
    "    else:\n",
    "        return np.zeros(shape=(0,) + shape_suffix, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7c73e1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a77bfe10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step.correct_attachment_point_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "53678a04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TraceStep(partial_node_features=array([[ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  4.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ]],\n",
       "       dtype=float32), partial_node_categorical_features=array([129]), partial_adjacency_lists=[array([], shape=(0, 2), dtype=int32), array([], shape=(0, 2), dtype=int32), array([], shape=(0, 2), dtype=int32)], correct_edge_choices=array([], dtype=float32), valid_edge_choices=array([], shape=(0, 2), dtype=int32), edge_features=array([], shape=(0, 3), dtype=float32), correct_edge_types=array([], shape=(0, 3), dtype=int32), valid_edge_types=array([], shape=(0, 3), dtype=float64), focus_node=0, correct_attachment_point_choice=None, valid_attachment_point_choices=array([], dtype=float64), correct_node_type_choices=['O']),\n",
       " TraceStep(partial_node_features=array([[ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  3.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  2.   ,  0.   ,  0.   ,  0.   , 15.999,\n",
       "          2.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  3.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  2.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  1.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  2.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  1.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  2.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  1.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  3.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  3.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  2.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  2.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  2.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  2.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  2.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  2.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  2.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  2.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  3.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  3.   ,  0.   ,  0.   ,  0.   , 14.007,\n",
       "          3.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  3.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  2.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  2.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "        [ 0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   , 12.011,\n",
       "          4.   ,  3.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ]],\n",
       "       dtype=float32), partial_node_categorical_features=array([129, 130, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,  69,\n",
       "         69,  69,  69,  69]), partial_adjacency_lists=[array([[ 1,  0],\n",
       "        [ 2,  1],\n",
       "        [ 4,  3],\n",
       "        [ 6,  5],\n",
       "        [ 7,  2],\n",
       "        [ 8,  7],\n",
       "        [ 9,  8],\n",
       "        [10,  9],\n",
       "        [11, 10],\n",
       "        [11,  6],\n",
       "        [13, 12],\n",
       "        [14, 13],\n",
       "        [15, 13],\n",
       "        [16, 15],\n",
       "        [ 0,  1],\n",
       "        [ 1,  2],\n",
       "        [ 3,  4],\n",
       "        [ 5,  6],\n",
       "        [ 2,  7],\n",
       "        [ 7,  8],\n",
       "        [ 8,  9],\n",
       "        [ 9, 10],\n",
       "        [10, 11],\n",
       "        [ 6, 11],\n",
       "        [12, 13],\n",
       "        [13, 14],\n",
       "        [13, 15],\n",
       "        [15, 16]], dtype=int32), array([[3, 2],\n",
       "        [5, 4],\n",
       "        [7, 6],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7]], dtype=int32), array([], shape=(0, 2), dtype=int32)], correct_edge_choices=array([], dtype=float32), valid_edge_choices=array([], shape=(0, 2), dtype=int32), edge_features=array([], shape=(0, 3), dtype=float32), correct_edge_types=array([], shape=(0, 3), dtype=int32), valid_edge_types=array([], shape=(0, 3), dtype=float64), focus_node=12, correct_attachment_point_choice=12, valid_attachment_point_choices=array([12, 15, 16]), correct_node_type_choices=None))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tmp[0], step2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee6acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f197646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "tmp = []\n",
    "for step in train[1]:\n",
    "    count += 1\n",
    "    tmp.append(step)\n",
    "    if step.correct_attachment_point_choice is not None:\n",
    "        print(count)\n",
    "        step2 = step\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab9a770f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COC=O']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.correct_first_node_type_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c0dedcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7fb98d077b30>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "Chem.MolFromSmiles('COC=O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18918b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
