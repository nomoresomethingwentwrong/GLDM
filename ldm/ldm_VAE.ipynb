{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b3d8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('/data/conghao001/diffusion_model/latent-diffusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a9c1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ldm.models.diffusion.ddpm import DDPM, DiffusionWrapper, disabled_train\n",
    "from ldm.models.diffusion.ddim import DDIMSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c382989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ldm.util import log_txt_as_img, exists, default, ismap, isimage, mean_flat, count_params, instantiate_from_config, get_obj_from_str\n",
    "from pytorch_lightning.utilities.distributed import rank_zero_only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "483c384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47443cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "__conditioning_keys__ = {'concat': 'c_concat',\n",
    "                         'crossattn': 'c_crossattn',\n",
    "                         'adm': 'y'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cc46522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DiffusionWrapper(pl.LightningModule):\n",
    "#     def __init__(self, diff_model_config, conditioning_key):\n",
    "#         super().__init__()\n",
    "#         self.diffusion_model = instantiate_from_config(diff_model_config)\n",
    "#         self.conditioning_key = conditioning_key\n",
    "#         assert self.conditioning_key in [None, 'concat', 'crossattn', 'hybrid', 'adm']\n",
    "\n",
    "#     def forward(self, x, t, c_concat: list = None, c_crossattn: list = None):\n",
    "#         if self.conditioning_key is None:\n",
    "#             out = self.diffusion_model(x, t)\n",
    "#         elif self.conditioning_key == 'concat':\n",
    "#             xc = torch.cat([x] + c_concat, dim=1)\n",
    "#             out = self.diffusion_model(xc, t)\n",
    "#         elif self.conditioning_key == 'crossattn':\n",
    "#             cc = torch.cat(c_crossattn, 1)\n",
    "#             out = self.diffusion_model(x, t, context=cc)\n",
    "#         elif self.conditioning_key == 'hybrid':\n",
    "#             xc = torch.cat([x] + c_concat, dim=1)\n",
    "#             cc = torch.cat(c_crossattn, 1)\n",
    "#             out = self.diffusion_model(xc, t, context=cc)\n",
    "#         elif self.conditioning_key == 'adm':\n",
    "#             cc = c_crossattn[0]\n",
    "#             out = self.diffusion_model(x, t, y=cc)\n",
    "#         else:\n",
    "#             raise NotImplementedError()\n",
    "\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a63da04",
   "metadata": {},
   "source": [
    "# Rewrite the ldm model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b02163",
   "metadata": {},
   "source": [
    "~~1. get_input function can be removed: it's supposed to get the input from batch with regard to key (first stage model input or cond stage model input), since the original model can have different cond stage keys, but in our case the cond input is always gene expr~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be24c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conghao001/miniconda3/envs/druggen/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:258: LightningDeprecationWarning: `pytorch_lightning.utilities.distributed.rank_zero_only` has been deprecated in v1.8.1 and will be removed in v1.10.0. You can import it from `pytorch_lightning.utilities` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "class LatentDiffusion(DDPM):\n",
    "    def __init__(self,\n",
    "                 first_stage_config,\n",
    "                 cond_stage_config,\n",
    "                 dataset, \n",
    "                 batch_size,\n",
    "                 first_stage_params,\n",
    "                 first_stage_ckpt,\n",
    "                 num_timesteps_cond=None,\n",
    "                 cond_stage_key=\"gene_expressions\",    \n",
    "                 cond_stage_trainable=False,    # we can either use pretrained MLP or train a new one\n",
    "                 concat_mode=True,\n",
    "                 cond_stage_forward=None,\n",
    "                 conditioning_key=None,    # by default, concat mode is used\n",
    "                 scale_factor=1.0,\n",
    "                 scale_by_std=False,\n",
    "                 *args, **kwargs):\n",
    "        self.num_timesteps_cond = default(num_timesteps_cond, 1)\n",
    "        self.scale_by_std = scale_by_std\n",
    "        assert self.num_timesteps_cond <= kwargs['timesteps']\n",
    "        \n",
    "        # to init the first stage model\n",
    "#         self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "#         self.first_stage_params = first_stage_params\n",
    "#         self.first_stage_ckpt = first_stage_ckpt\n",
    "        \n",
    "        # for backwards compatibility after implementation of DiffusionWrapper\n",
    "        if conditioning_key is None:\n",
    "            conditioning_key = 'concat' if concat_mode else 'crossattn'\n",
    "        if cond_stage_config == '__is_unconditional__':    # to train unconditional diff model\n",
    "            conditioning_key = None\n",
    "            \n",
    "        ckpt_path = kwargs.pop(\"ckpt_path\", None)    # this is for the diff model ckpt, not vaes\n",
    "        ignore_keys = kwargs.pop(\"ignore_keys\", [])\n",
    "        super().__init__(conditioning_key=conditioning_key, *args, **kwargs)    # DiffusionWrapper is called here\n",
    "        \n",
    "        self.concat_mode = concat_mode\n",
    "        self.cond_stage_trainable = cond_stage_trainable\n",
    "        self.cond_stage_key = cond_stage_key\n",
    "        try:\n",
    "            self.num_downs = len(first_stage_config.params.ddconfig.ch_mult) - 1\n",
    "        except:\n",
    "            self.num_downs = 0\n",
    "        if not scale_by_std:\n",
    "            self.scale_factor = scale_factor\n",
    "        else:\n",
    "            self.register_buffer('scale_factor', torch.tensor(scale_factor))\n",
    "        self.instantiate_first_stage(first_stage_config, first_stage_params, dataset, first_stage_ckpt)    # first stage model is initiated here\n",
    "#         self.instantiate_cond_stage(cond_stage_config)    # let's remove this and directly input the gene expr to unet\n",
    "        self.cond_stage_forward = cond_stage_forward\n",
    "        self.clip_denoised = False\n",
    "        self.bbox_tokenizer = None  \n",
    "\n",
    "        self.restarted_from_ckpt = False\n",
    "        if ckpt_path is not None:\n",
    "            self.init_from_ckpt(ckpt_path, ignore_keys)\n",
    "            self.restarted_from_ckpt = True\n",
    "            \n",
    "    def make_cond_schedule(self, ):\n",
    "        self.cond_ids = torch.full(size=(self.num_timesteps,), fill_value=self.num_timesteps - 1, dtype=torch.long)\n",
    "        ids = torch.round(torch.linspace(0, self.num_timesteps - 1, self.num_timesteps_cond)).long()\n",
    "        self.cond_ids[:self.num_timesteps_cond] = ids\n",
    "        \n",
    "    @rank_zero_only\n",
    "    @torch.no_grad()\n",
    "    def on_train_batch_start(self, batch, batch_idx):\n",
    "        # only for very first batch\n",
    "        # this function should be called at the beginning of trainer.fit_loop, not sure if it will be called in trainer.fit\n",
    "        if self.scale_by_std and self.current_epoch == 0 and self.global_step == 0 and batch_idx == 0 and not self.restarted_from_ckpt:\n",
    "            assert self.scale_factor == 1., 'rather not use custom rescaling and std-rescaling simultaneously'\n",
    "            # set rescale weight to 1./std of encodings\n",
    "            print(\"### USING STD-RESCALING ###\")\n",
    "#             x = super().get_input(batch, self.first_stage_key)    # this is not necessary as the whole batch is always passed together\n",
    "            x = batch\n",
    "            x = x.to(self.device)\n",
    "            encoder_posterior, partial_reprs, node_reprs = self.encode_first_stage(x)\n",
    "            self.partial_reprs = partial_reprs\n",
    "            self.node_reprs = node_reprs\n",
    "            \n",
    "            z = self.get_first_stage_encoding(encoder_posterior).detach()\n",
    "            del self.scale_factor\n",
    "            self.register_buffer('scale_factor', 1. / z.flatten().std())\n",
    "            print(f\"setting self.scale_factor to {self.scale_factor}\")\n",
    "            print(\"### USING STD-RESCALING ###\")\n",
    "            \n",
    "    def register_schedule(self,\n",
    "                          given_betas=None, beta_schedule=\"linear\", timesteps=1000,\n",
    "                          linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3):\n",
    "        super().register_schedule(given_betas, beta_schedule, timesteps, linear_start, linear_end, cosine_s)\n",
    "\n",
    "        self.shorten_cond_schedule = self.num_timesteps_cond > 1\n",
    "        if self.shorten_cond_schedule:\n",
    "            self.make_cond_schedule()\n",
    "            \n",
    "    def init_first_stage_model(self, config, ckpt, **kwargs):\n",
    "        # vae kwargs: params, dataset, using_lincs, include_predict_gene_exp_mlp = False, num_train_batches=1, batch_size=1, use_clamp_log_var = False\n",
    "        if not \"target\" in config:\n",
    "            if config == '__is_first_stage__':\n",
    "                return None\n",
    "            elif config == \"__is_unconditional__\":\n",
    "                return None\n",
    "            raise KeyError(\"Expected key `target` to instantiate.\")\n",
    "        model = get_obj_from_str(config[\"target\"])\n",
    "        model = model.load_from_checkpoint(ckpt, **kwargs)\n",
    "\n",
    "        return model\n",
    "            \n",
    "    def instantiate_first_stage(self, config, params, dataset, ckpt):\n",
    "#         model = instantiate_from_config(config)    # TODO: rewrite with our model init function\n",
    "\n",
    "        if config['model_type'] == 'vae':\n",
    "            model = self.init_first_stage_model(config, ckpt, params=params, dataset=dataset, using_lincs=config['using_lincs'])\n",
    "        elif config['model_type'] == 'aae':\n",
    "            model = self.init_first_stage_model(\n",
    "                config, \n",
    "                ckpt, \n",
    "                params=params,\n",
    "                dataset=dataset,\n",
    "                using_lincs=config['using_lincs'],\n",
    "                using_wasserstein_loss=False,\n",
    "                using_gp=False,\n",
    "            )\n",
    "        elif config['model_type'] == 'wae':\n",
    "            model = self.init_first_stage_model(\n",
    "                config, \n",
    "                ckpt, \n",
    "                params=params,\n",
    "                dataset=dataset,\n",
    "                using_lincs=config['using_lincs'],\n",
    "                using_wasserstein_loss=True,\n",
    "                using_gp=True,\n",
    "            )\n",
    "        else: \n",
    "            raise NotImplementedError('first stage model type is not supported')\n",
    "        \n",
    "        self.first_stage_model = model.eval()\n",
    "        self.first_stage_model.train = disabled_train    # overwrite model's train function with the empty disabled_train\n",
    "        for param in self.first_stage_model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def instantiate_cond_stage(self, config):\n",
    "        # TODO: adapt this function\n",
    "        if not self.cond_stage_trainable:\n",
    "            if config == \"__is_first_stage__\":\n",
    "                print(\"Using first stage also as cond stage.\")\n",
    "                self.cond_stage_model = self.first_stage_model\n",
    "            elif config == \"__is_unconditional__\":\n",
    "                print(f\"Training {self.__class__.__name__} as an unconditional model.\")\n",
    "                self.cond_stage_model = None\n",
    "                # self.be_unconditional = True\n",
    "            else:\n",
    "                model = instantiate_from_config(config)\n",
    "                self.cond_stage_model = model.eval()\n",
    "                self.cond_stage_model.train = disabled_train\n",
    "                for param in self.cond_stage_model.parameters():\n",
    "                    param.requires_grad = False\n",
    "        else:\n",
    "            assert config != '__is_first_stage__'\n",
    "            assert config != '__is_unconditional__'\n",
    "            model = instantiate_from_config(config)\n",
    "            self.cond_stage_model = model\n",
    "            \n",
    "#     def _get_denoise_row_from_list(self, samples, desc='', force_no_decoder_quantization=False):\n",
    "#         # we may not need the denoising row?\n",
    "#         denoise_row = []\n",
    "#         for zd in tqdm(samples, desc=desc):\n",
    "#             denoise_row.append(self.decode_first_stage(zd.to(self.device),\n",
    "#                                                             force_not_quantize=force_no_decoder_quantization))\n",
    "#         n_imgs_per_row = len(denoise_row)\n",
    "#         denoise_row = torch.stack(denoise_row)  # n_log_step, n_row, C, H, W\n",
    "#         denoise_grid = rearrange(denoise_row, 'n b c h w -> b n c h w')\n",
    "#         denoise_grid = rearrange(denoise_grid, 'b n c h w -> (b n) c h w')\n",
    "#         denoise_grid = make_grid(denoise_grid, nrow=n_imgs_per_row)\n",
    "#         return denoise_grid\n",
    "\n",
    "    def get_first_stage_encoding(self, encoder_posterior):\n",
    "        # we don't have the diagonal gaussian dist\n",
    "#         if isinstance(encoder_posterior, DiagonalGaussianDistribution):\n",
    "#             z = encoder_posterior.sample()\n",
    "        if isinstance(encoder_posterior, torch.Tensor):\n",
    "            z = encoder_posterior\n",
    "        else:\n",
    "            raise NotImplementedError(f\"encoder_posterior of type '{type(encoder_posterior)}' not yet implemented\")\n",
    "        return self.scale_factor * z\n",
    "    \n",
    "    def get_learned_conditioning(self, c):\n",
    "        if self.cond_stage_forward is None:\n",
    "            if hasattr(self.cond_stage_model, 'encode') and callable(self.cond_stage_model.encode):\n",
    "                c = self.cond_stage_model.encode(c)\n",
    "                if isinstance(c, DiagonalGaussianDistribution):\n",
    "                    c = c.mode()\n",
    "            else:\n",
    "                c = self.cond_stage_model(c)\n",
    "        else:\n",
    "            # TODO: if our cond model is a GenericMLP, set self.cond_stage_forward as the forward function of self.cond_stage_model\n",
    "            assert hasattr(self.cond_stage_model, self.cond_stage_forward)\n",
    "            c = getattr(self.cond_stage_model, self.cond_stage_forward)(c)\n",
    "        return c\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def get_input(self, batch, return_first_stage_outputs=False, force_c_encode=False,\n",
    "                  cond_key=None, return_original_cond=False, bs=None):\n",
    "        # TODO: rewrite this function to get the mol input and the gene expr input\n",
    "        # TODO: this function is called in shared_step (used in training/val_step for lightening model). adapt them as well\n",
    "        '''\n",
    "        this function is to get inputs for the diff model. \n",
    "        It should only return the latent repr to get diffused and the cond vector to control the diffusion\n",
    "        \n",
    "        output of this function: \n",
    "            z: latent repr of the first stage model\n",
    "            partial_repr?? no need to have this\n",
    "            c: output of the cond stage model (or it can be the gene expr directly??)\n",
    "        '''\n",
    "        \n",
    "#         x = super().get_input(batch, k)\n",
    "        x = batch\n",
    "        if bs is not None:\n",
    "            x = x[:bs]\n",
    "        x = x.to(self.device)\n",
    "        encoder_posterior, partial_reprs, node_reprs = self.encode_first_stage(x)\n",
    "        z = self.get_first_stage_encoding(encoder_posterior).detach()\n",
    "        self.partial_reprs = partial_reprs\n",
    "        self.node_reprs = node_reprs\n",
    "\n",
    "        if self.model.conditioning_key is not None:    # should be concat or crossattn\n",
    "            if cond_key is None:\n",
    "                cond_key = self.cond_stage_key\n",
    "\n",
    "            if cond_key == 'gene_expressions':\n",
    "                xc = torch.cat((batch[cond_key], batch['dose'].unsqueeze(-1)), dim=-1)\n",
    "            else:\n",
    "                xc = None\n",
    "                raise NotImplementedError('condition key is not supported')\n",
    "                \n",
    "            # to train the cond model (currently let's input gene expr directly)\n",
    "            '''\n",
    "            if not self.cond_stage_trainable or force_c_encode:\n",
    "                if isinstance(xc, dict) or isinstance(xc, list):\n",
    "                    # import pudb; pudb.set_trace()\n",
    "                    c = self.get_learned_conditioning(xc)\n",
    "                else:\n",
    "                    c = self.get_learned_conditioning(xc.to(self.device))\n",
    "            else:\n",
    "                c = xc\n",
    "            '''\n",
    "            c = xc\n",
    "                \n",
    "            if bs is not None:\n",
    "                c = c[:bs]\n",
    "\n",
    "        else:\n",
    "            c = None\n",
    "            xc = None\n",
    "            \n",
    "        # reshape z and c\n",
    "#         print('original z size:', z.size())\n",
    "        z = z.view((self.batch_size, -1, z.size(-1)))\n",
    "#         print('after resizing', z.size())\n",
    "        \n",
    "        out = [z, c]\n",
    "        if return_first_stage_outputs:\n",
    "            xrec = self.decode_first_stage(z, batch)    # this shouldn't happen, decoder will return a lot of things\n",
    "            out.extend([x, xrec])\n",
    "        if return_original_cond:\n",
    "            out.append(xc)\n",
    "        return out\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def decode_first_stage(self, z, batch, predict_cids=False, force_not_quantize=False):\n",
    "        z = 1. / self.scale_factor * z\n",
    "        (\n",
    "            first_node_type_logits,\n",
    "            node_type_logits,\n",
    "            edge_candidate_logits,\n",
    "            edge_type_logits,\n",
    "            attachment_point_selection_logits,\n",
    "        ) = self.first_stage_model.decoder(\n",
    "            input_molecule_representations=z,\n",
    "            graph_representations=self.partial_reprs,\n",
    "            graphs_requiring_node_choices=batch.correct_node_type_choices_batch.unique(),\n",
    "            # edge selection\n",
    "            node_representations=self.node_reprs,\n",
    "            num_graphs_in_batch=len(batch.ptr) - 1,\n",
    "            focus_node_idx_in_batch=batch.focus_node,\n",
    "            node_to_graph_map=batch.batch,\n",
    "            candidate_edge_targets=batch.valid_edge_choices[:, 1].long(),\n",
    "            candidate_edge_features=batch.edge_features,\n",
    "            # attachment selection\n",
    "            candidate_attachment_points=batch.valid_attachment_point_choices.long(),\n",
    "        )\n",
    "        return [first_node_type_logits, node_type_logits, edge_candidate_logits, edge_type_logits, attachment_point_selection_logits]\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def encode_first_stage(self, batch):\n",
    "        # other repr from partial encoder should also be done and passed to self, so that decoder can access to them\n",
    "        input_molecule_representations = self.first_stage_model.full_graph_encoder(\n",
    "            original_graph_node_categorical_features=batch.original_graph_node_categorical_features,\n",
    "            node_features=batch.original_graph_x.float(),\n",
    "            edge_index=batch.original_graph_edge_index,\n",
    "            edge_features=batch.original_graph_edge_features,  # can be edge_type or edge_attr\n",
    "            batch_index=batch.original_graph_x_batch,\n",
    "        )\n",
    "        partial_graph_representations, node_representations = self.first_stage_model.partial_graph_encoder(\n",
    "            partial_graph_node_categorical_features=batch.partial_node_categorical_features,\n",
    "            node_features=batch.x,\n",
    "            edge_index=batch.edge_index.long(),\n",
    "            edge_features=batch.partial_graph_edge_features,\n",
    "            graph_to_focus_node_map=batch.focus_node,\n",
    "            candidate_attachment_points=batch.valid_attachment_point_choices,\n",
    "            batch_index=batch.batch,\n",
    "        )\n",
    "        return input_molecule_representations, partial_graph_representations, node_representations\n",
    "    \n",
    "    def shared_step(self, batch, **kwargs):\n",
    "        print(batch)\n",
    "        # skip a weird batch\n",
    "        if batch['dose'].size(0) != 1000:\n",
    "            raise ValueError('channel number is not 1000!')\n",
    "            \n",
    "        # pass the batch data to decoder via self\n",
    "        self.batch = batch\n",
    "\n",
    "        # x here is actually latent repr z. it's written as x to be consistent with the DDPM theory.\n",
    "        x, c = self.get_input(batch)\n",
    "        loss = self(x, c)\n",
    "        return loss\n",
    "    \n",
    "    def forward(self, x, c, *args, **kwargs):\n",
    "        t = torch.randint(0, self.num_timesteps, (x.shape[0],), device=self.device).long()\n",
    "        if self.model.conditioning_key is not None:\n",
    "            assert c is not None\n",
    "            if self.cond_stage_trainable:\n",
    "                c = self.get_learned_conditioning(c)\n",
    "            if self.shorten_cond_schedule:  # TODO: drop this option\n",
    "                tc = self.cond_ids[t].to(self.device)\n",
    "                c = self.q_sample(x_start=c, t=tc, noise=torch.randn_like(c.float()))\n",
    "        return self.p_losses(x, c, t, *args, **kwargs)\n",
    "    \n",
    "    def apply_model(self, x_noisy, t, cond, return_ids=False):\n",
    "\n",
    "        if isinstance(cond, dict):\n",
    "            # hybrid case, cond is exptected to be a dict\n",
    "            pass\n",
    "        else:\n",
    "            if not isinstance(cond, list):\n",
    "                cond = [cond]\n",
    "            key = 'c_concat' if self.model.conditioning_key == 'concat' else 'c_crossattn'\n",
    "            cond = {key: cond}\n",
    "\n",
    "        # pass the cond (gene expr) as c_concat in DiffusionWrapper model forward function\n",
    "        # then x_noisy and cond will be concatenated and passed to U-Net model forward\n",
    "        \n",
    "        x_recon = self.model(x_noisy, t, **cond)\n",
    "\n",
    "        if isinstance(x_recon, tuple) and not return_ids:\n",
    "            return x_recon[0]\n",
    "        else:\n",
    "            return x_recon\n",
    "        \n",
    "    def _predict_eps_from_xstart(self, x_t, t, pred_xstart):\n",
    "        return (extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t - pred_xstart) / \\\n",
    "               extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape)\n",
    "    \n",
    "    def _prior_bpd(self, x_start):\n",
    "        \"\"\"\n",
    "        Get the prior KL term for the variational lower-bound, measured in\n",
    "        bits-per-dim.\n",
    "        This term can't be optimized, as it only depends on the encoder.\n",
    "        :param x_start: the [N x C x ...] tensor of inputs.\n",
    "        :return: a batch of [N] KL values (in bits), one per batch element.\n",
    "        \"\"\"\n",
    "        batch_size = x_start.shape[0]\n",
    "        t = torch.tensor([self.num_timesteps - 1] * batch_size, device=x_start.device)\n",
    "        qt_mean, _, qt_log_variance = self.q_mean_variance(x_start, t)\n",
    "        kl_prior = normal_kl(mean1=qt_mean, logvar1=qt_log_variance, mean2=0.0, logvar2=0.0)\n",
    "        return mean_flat(kl_prior) / np.log(2.0)\n",
    "    \n",
    "    def p_losses(self, x_start, cond, t, noise=None):\n",
    "#         print('x_start size:', x_start.size())\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)\n",
    "#         print('x noisy size:', x_noisy.size())\n",
    "        model_output = self.apply_model(x_noisy, t, cond)\n",
    "\n",
    "        loss_dict = {}\n",
    "        prefix = 'train' if self.training else 'val'\n",
    "\n",
    "        if self.parameterization == \"x0\":\n",
    "            target = x_start\n",
    "        elif self.parameterization == \"eps\":\n",
    "            target = noise\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "#         print('size of output and target:', model_output.size(), target.size())\n",
    "        loss_simple0 = self.get_loss(model_output, target, mean=False)\n",
    "        # change the mean dim from [1, 2, 3] to [1, 2] as our latent repr is 1D\n",
    "        loss_simple = loss_simple0.mean([1, 2])\n",
    "        loss_dict.update({f'{prefix}/loss_simple': loss_simple.mean()})\n",
    "\n",
    "#         print('self device:', self.device)\n",
    "#         print('original t device:', t.device)\n",
    "#         t = t.to(self.device)\n",
    "        \n",
    "#         print('logvar device:', self.logvar.device)\n",
    "        self.logvar = self.logvar.to(self.device)\n",
    "        logvar_t = self.logvar[t].to(self.device)\n",
    "        loss = loss_simple / torch.exp(logvar_t) + logvar_t\n",
    "        # loss = loss_simple / torch.exp(self.logvar) + self.logvar\n",
    "        if self.learn_logvar:\n",
    "            loss_dict.update({f'{prefix}/loss_gamma': loss.mean()})\n",
    "            loss_dict.update({'logvar': self.logvar.data.mean()})\n",
    "\n",
    "        loss = self.l_simple_weight * loss.mean()\n",
    "\n",
    "        # change the mean dim from [1, 2, 3] to [1, 2] as our latent repr is 1D\n",
    "        loss_vlb = self.get_loss(model_output, target, mean=False).mean(dim=(1, 2))\n",
    "        loss_vlb = (self.lvlb_weights[t] * loss_vlb).mean()\n",
    "        loss_dict.update({f'{prefix}/loss_vlb': loss_vlb})\n",
    "        loss += (self.original_elbo_weight * loss_vlb)\n",
    "        loss_dict.update({f'{prefix}/loss': loss})\n",
    "\n",
    "        return loss, loss_dict\n",
    "    \n",
    "    def p_mean_variance(self, x, c, t, clip_denoised: bool, return_codebook_ids=False, quantize_denoised=False,\n",
    "                        return_x0=False, score_corrector=None, corrector_kwargs=None):\n",
    "        t_in = t\n",
    "        model_out = self.apply_model(x, t_in, c, return_ids=return_codebook_ids)\n",
    "\n",
    "        if score_corrector is not None:\n",
    "            assert self.parameterization == \"eps\"\n",
    "            model_out = score_corrector.modify_score(self, model_out, x, t, c, **corrector_kwargs)\n",
    "\n",
    "        if return_codebook_ids:\n",
    "            model_out, logits = model_out\n",
    "\n",
    "        if self.parameterization == \"eps\":\n",
    "            x_recon = self.predict_start_from_noise(x, t=t, noise=model_out)\n",
    "        elif self.parameterization == \"x0\":\n",
    "            x_recon = model_out\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        if clip_denoised:\n",
    "            x_recon.clamp_(-1., 1.)\n",
    "        if quantize_denoised:\n",
    "            x_recon, _, [_, _, indices] = self.first_stage_model.quantize(x_recon)\n",
    "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n",
    "        if return_codebook_ids:\n",
    "            return model_mean, posterior_variance, posterior_log_variance, logits\n",
    "        elif return_x0:\n",
    "            return model_mean, posterior_variance, posterior_log_variance, x_recon\n",
    "        else:\n",
    "            return model_mean, posterior_variance, posterior_log_variance\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x, c, t, clip_denoised=False, repeat_noise=False,\n",
    "                 return_codebook_ids=False, quantize_denoised=False, return_x0=False,\n",
    "                 temperature=1., noise_dropout=0., score_corrector=None, corrector_kwargs=None):\n",
    "        b, *_, device = *x.shape, x.device\n",
    "        outputs = self.p_mean_variance(x=x, c=c, t=t, clip_denoised=clip_denoised,\n",
    "                                       return_codebook_ids=return_codebook_ids,\n",
    "                                       quantize_denoised=quantize_denoised,\n",
    "                                       return_x0=return_x0,\n",
    "                                       score_corrector=score_corrector, corrector_kwargs=corrector_kwargs)\n",
    "        if return_codebook_ids:\n",
    "            raise DeprecationWarning(\"Support dropped.\")\n",
    "            model_mean, _, model_log_variance, logits = outputs\n",
    "        elif return_x0:\n",
    "            model_mean, _, model_log_variance, x0 = outputs\n",
    "        else:\n",
    "            model_mean, _, model_log_variance = outputs\n",
    "\n",
    "        noise = noise_like(x.shape, device, repeat_noise) * temperature\n",
    "        if noise_dropout > 0.:\n",
    "            noise = torch.nn.functional.dropout(noise, p=noise_dropout)\n",
    "        # no noise when t == 0\n",
    "        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))\n",
    "\n",
    "        if return_codebook_ids:\n",
    "            return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise, logits.argmax(dim=1)\n",
    "        if return_x0:\n",
    "            return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise, x0\n",
    "        else:\n",
    "            return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def progressive_denoising(self, cond, shape, verbose=True, callback=None, quantize_denoised=False,\n",
    "                              img_callback=None, mask=None, x0=None, temperature=1., noise_dropout=0.,\n",
    "                              score_corrector=None, corrector_kwargs=None, batch_size=None, x_T=None, start_T=None,\n",
    "                              log_every_t=None):\n",
    "        if not log_every_t:\n",
    "            log_every_t = self.log_every_t\n",
    "        timesteps = self.num_timesteps\n",
    "        if batch_size is not None:\n",
    "            b = batch_size if batch_size is not None else shape[0]\n",
    "            shape = [batch_size] + list(shape)\n",
    "        else:\n",
    "            b = batch_size = shape[0]\n",
    "        \n",
    "        # img is standard normal dist or the last timestep x_T\n",
    "        if x_T is None:\n",
    "            img = torch.randn(shape, device=self.device)\n",
    "        else:\n",
    "            img = x_T\n",
    "        intermediates = []\n",
    "        if cond is not None:\n",
    "            if isinstance(cond, dict):\n",
    "                cond = {key: cond[key][:batch_size] if not isinstance(cond[key], list) else\n",
    "                list(map(lambda x: x[:batch_size], cond[key])) for key in cond}\n",
    "            else:\n",
    "                cond = [c[:batch_size] for c in cond] if isinstance(cond, list) else cond[:batch_size]\n",
    "\n",
    "        if start_T is not None:\n",
    "            timesteps = min(timesteps, start_T)\n",
    "        iterator = tqdm(reversed(range(0, timesteps)), desc='Progressive Generation',\n",
    "                        total=timesteps) if verbose else reversed(\n",
    "            range(0, timesteps))\n",
    "        if type(temperature) == float:\n",
    "            temperature = [temperature] * timesteps\n",
    "\n",
    "        for i in iterator:\n",
    "            ts = torch.full((b,), i, device=self.device, dtype=torch.long)\n",
    "            if self.shorten_cond_schedule:\n",
    "                assert self.model.conditioning_key != 'hybrid'\n",
    "                tc = self.cond_ids[ts].to(cond.device)\n",
    "                cond = self.q_sample(x_start=cond, t=tc, noise=torch.randn_like(cond))    # add noise to the cond?\n",
    "\n",
    "            img, x0_partial = self.p_sample(img, cond, ts,\n",
    "                                            clip_denoised=self.clip_denoised,\n",
    "                                            quantize_denoised=quantize_denoised, return_x0=True,\n",
    "                                            temperature=temperature[i], noise_dropout=noise_dropout,\n",
    "                                            score_corrector=score_corrector, corrector_kwargs=corrector_kwargs)\n",
    "            if mask is not None:\n",
    "                assert x0 is not None\n",
    "                img_orig = self.q_sample(x0, ts)\n",
    "                img = img_orig * mask + (1. - mask) * img\n",
    "\n",
    "            if i % log_every_t == 0 or i == timesteps - 1:\n",
    "                intermediates.append(x0_partial)\n",
    "            if callback: callback(i)\n",
    "            if img_callback: img_callback(img, i)\n",
    "        return img, intermediates\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, cond, shape, return_intermediates=False,\n",
    "                      x_T=None, verbose=True, callback=None, timesteps=None, quantize_denoised=False,\n",
    "                      mask=None, x0=None, img_callback=None, start_T=None,\n",
    "                      log_every_t=None):\n",
    "\n",
    "        if not log_every_t:\n",
    "            log_every_t = self.log_every_t\n",
    "        device = self.betas.device\n",
    "        b = shape[0]\n",
    "        if x_T is None:\n",
    "            img = torch.randn(shape, device=device)\n",
    "        else:\n",
    "            img = x_T\n",
    "\n",
    "        intermediates = [img]\n",
    "        if timesteps is None:\n",
    "            timesteps = self.num_timesteps\n",
    "\n",
    "        if start_T is not None:\n",
    "            timesteps = min(timesteps, start_T)\n",
    "        iterator = tqdm(reversed(range(0, timesteps)), desc='Sampling t', total=timesteps) if verbose else reversed(\n",
    "            range(0, timesteps))\n",
    "\n",
    "        if mask is not None:\n",
    "            assert x0 is not None\n",
    "            assert x0.shape[2:3] == mask.shape[2:3]  # spatial size has to match\n",
    "\n",
    "        for i in iterator:\n",
    "            ts = torch.full((b,), i, device=device, dtype=torch.long)\n",
    "            if self.shorten_cond_schedule:\n",
    "                assert self.model.conditioning_key != 'hybrid'\n",
    "                tc = self.cond_ids[ts].to(cond.device)\n",
    "                cond = self.q_sample(x_start=cond, t=tc, noise=torch.randn_like(cond))\n",
    "\n",
    "            img = self.p_sample(img, cond, ts,\n",
    "                                clip_denoised=self.clip_denoised,\n",
    "                                quantize_denoised=quantize_denoised)\n",
    "            if mask is not None:\n",
    "                img_orig = self.q_sample(x0, ts)\n",
    "                img = img_orig * mask + (1. - mask) * img\n",
    "\n",
    "            if i % log_every_t == 0 or i == timesteps - 1:\n",
    "                intermediates.append(img)\n",
    "            if callback: callback(i)\n",
    "            if img_callback: img_callback(img, i)\n",
    "\n",
    "        if return_intermediates:\n",
    "            return img, intermediates\n",
    "        return img\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample(self, cond, batch_size=16, return_intermediates=False, x_T=None,\n",
    "               verbose=True, timesteps=None, quantize_denoised=False,\n",
    "               mask=None, x0=None, shape=None,**kwargs):\n",
    "        if shape is None:\n",
    "            shape = (batch_size, self.channels, self.image_size, self.image_size)\n",
    "        if cond is not None:\n",
    "            if isinstance(cond, dict):\n",
    "                cond = {key: cond[key][:batch_size] if not isinstance(cond[key], list) else\n",
    "                list(map(lambda x: x[:batch_size], cond[key])) for key in cond}\n",
    "            else:\n",
    "                cond = [c[:batch_size] for c in cond] if isinstance(cond, list) else cond[:batch_size]\n",
    "        return self.p_sample_loop(cond,\n",
    "                                  shape,\n",
    "                                  return_intermediates=return_intermediates, x_T=x_T,\n",
    "                                  verbose=verbose, timesteps=timesteps, quantize_denoised=quantize_denoised,\n",
    "                                  mask=mask, x0=x0)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_log(self,cond,batch_size,ddim, ddim_steps,**kwargs):\n",
    "        # we can call this function outside to get the sampled latent reprs\n",
    "        # x_T can be none, it will be set as randn automatically\n",
    "        # x0 can also none, it's only applicable when mask is not none. (guess mask is for some inpainting function?)\n",
    "        if ddim:\n",
    "            ddim_sampler = DDIMSampler(self)\n",
    "            shape = (self.channels, self.image_size, self.image_size)\n",
    "            samples, intermediates =ddim_sampler.sample(ddim_steps,batch_size,\n",
    "                                                        shape,cond,verbose=False,**kwargs)\n",
    "\n",
    "        else:\n",
    "            samples, intermediates = self.sample(cond=cond, batch_size=batch_size,\n",
    "                                                 return_intermediates=True,**kwargs)\n",
    "\n",
    "        return samples, intermediates\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def log_mol(self, batch):\n",
    "        # adapt log_images to record the generated molecules\n",
    "        return \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        lr = self.learning_rate\n",
    "        params = list(self.model.parameters())\n",
    "        if self.cond_stage_trainable:\n",
    "            print(f\"{self.__class__.__name__}: Also optimizing conditioner params!\")\n",
    "            params = params + list(self.cond_stage_model.parameters())\n",
    "        if self.learn_logvar:\n",
    "            print('Diffusion model optimizing logvar')\n",
    "            params.append(self.logvar)\n",
    "        opt = torch.optim.AdamW(params, lr=lr)\n",
    "        if self.use_scheduler:\n",
    "            assert 'target' in self.scheduler_config\n",
    "            scheduler = instantiate_from_config(self.scheduler_config)\n",
    "\n",
    "            print(\"Setting up LambdaLR scheduler...\")\n",
    "            scheduler = [\n",
    "                {\n",
    "                    'scheduler': LambdaLR(opt, lr_lambda=scheduler.schedule),\n",
    "                    'interval': 'step',\n",
    "                    'frequency': 1\n",
    "                }]\n",
    "            return [opt], scheduler\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ee3d56",
   "metadata": {},
   "source": [
    "# Direct changes to the LDM source codeÂ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c41e4",
   "metadata": {},
   "source": [
    "- ~~in `latent-diffusion/ldm/modules/diffusionmodules/util.py` normalization function, change GroupNorm from dividing channels into 32 groups to 1 group~~\n",
    "- add `batch_size = self.batch_size` in each *log* and *log_dict* function in the DDPM module, to get rid of the lightning warning of infering batch size\n",
    "- in attention.py-*SpatialTransformer*, change from 2D into 1D case. See `/data/conghao001/diffusion_model/latent-diffusion/ldm/modules/attention.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a475873e",
   "metadata": {},
   "source": [
    "# Try the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cd0b34",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ca9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6e0a7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 01:06:44.564462: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from dataset import LincsDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from omegaconf import OmegaConf\n",
    "from model_utils import get_params\n",
    "from tqdm import tqdm\n",
    "from pytorch_lightning.trainer import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09784413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'base_learning_rate': 5e-05, 'target': 'ldm.models.diffusion.ddpm.LatentDiffusion', 'params': {'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 50, 'timesteps': 200, 'first_stage_key': 'image', 'cond_stage_key': 'gene_expressions', 'image_size': 512, 'channels': 1, 'cond_stage_trainable': False, 'conditioning_key': 'concat', 'monitor': 'val/loss_simple_ema', 'scale_factor': 1, 'use_ema': False, 'parameterization': 'eps'}, 'first_stage_config': {'target': 'model.BaseModel', 'model_type': 'vae', 'using_lincs': True, 'ckpt_path': '/data/conghao001/FYP/DrugDiscovery/first_stage_models/2023-03-11_23_33_36.921147/epoch=07-val_loss=0.60.ckpt'}, 'cond_stage_config': {'params': {'dim': 979, 'key': 'gene_expressions'}}, 'unet_config': {'target': 'ldm.modules.diffusionmodules.openaimodel.UNetModel', 'params': {'image_size': 512, 'in_channels': 1, 'out_channels': 1, 'model_channels': 64, 'dims': 1, 'attention_resolutions': [4, 2], 'num_res_blocks': 1, 'channel_mult': [1, 2, 3], 'num_head_channels': 8}}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_file = 'config/ddim_vae_con.yml'\n",
    "config = OmegaConf.load(config_file)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "719424d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 50, 'timesteps': 200, 'first_stage_key': 'image', 'cond_stage_key': 'gene_expressions', 'image_size': 512, 'channels': 1, 'cond_stage_trainable': False, 'conditioning_key': 'concat', 'monitor': 'val/loss_simple_ema', 'scale_factor': 1, 'use_ema': False, 'parameterization': 'eps'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldm_params = config['model']['params']\n",
    "ldm_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ff692",
   "metadata": {},
   "source": [
    "*TODO:* write this into config as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8768c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "batch_size = 1\n",
    "NUM_WORKERS = 4\n",
    "train_split1 = \"train_0\"\n",
    "valid_split = \"valid_0\"\n",
    "\n",
    "layer_type = \"FiLMConv\"\n",
    "model_architecture = 'vae'\n",
    "gradient_clip_val = 1.0\n",
    "max_lr = 1e-5\n",
    "gen_step_drop_probability = 0.5\n",
    "use_oclr_scheduler = True\n",
    "using_cyclical_anneal = False\n",
    "use_clamp_log_var = False\n",
    "\n",
    "raw_moler_trace_dataset_parent_folder = \"/data/ongh0068/guacamol/trace_dir\"\n",
    "# raw_moler_trace_dataset_parent_folder = \"/data/ongh0068/l1000/TRACE_DIR\"\n",
    "output_pyg_trace_dataset_parent_folder = (\n",
    "    \"/data/ongh0068/l1000/already_batched\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cfd82ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading controls gene expression...\n",
      "Loading tumour gene expression...\n",
      "Loading csv...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LincsDataset(794)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = LincsDataset(\n",
    "    root=\"/data/ongh0068\",\n",
    "    raw_moler_trace_dataset_parent_folder=raw_moler_trace_dataset_parent_folder,  # \"/data/ongh0068/l1000/trace_playground\",\n",
    "    output_pyg_trace_dataset_parent_folder=output_pyg_trace_dataset_parent_folder,\n",
    "    gene_exp_controls_file_path=\"/data/ongh0068/l1000/lincs/robust_normalized_controls.npz\",\n",
    "    gene_exp_tumour_file_path=\"/data/ongh0068/l1000/lincs/robust_normalized_tumors.npz\",\n",
    "    lincs_csv_file_path=\"/data/ongh0068/l1000/lincs/experiments_filtered.csv\",\n",
    "    split=train_split1,\n",
    "    gen_step_drop_probability=gen_step_drop_probability,\n",
    ")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41aae75e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolerDataBatch(x=[3796, 59], edge_index=[2, 7642], original_graph_edge_features=[14754], original_graph_node_categorical_features=[6757], focus_node=[253], partial_graph_edge_features=[7642], edge_features=[1597, 3], correct_edge_choices=[1597], correct_edge_choices_batch=[1597], correct_edge_choices_ptr=[254], num_correct_edge_choices=[253], stop_node_label=[253], valid_edge_choices=[1597, 2], valid_edge_choices_batch=[1597], valid_edge_choices_ptr=[254], valid_edge_types=[131, 3], correct_edge_types=[131, 3], correct_edge_types_batch=[131], correct_edge_types_ptr=[254], partial_node_categorical_features=[3796], correct_attachment_point_choice=[17], correct_attachment_point_choice_batch=[17], correct_attachment_point_choice_ptr=[254], correct_node_type_choices=[116, 166], correct_node_type_choices_batch=[116], correct_node_type_choices_ptr=[254], correct_first_node_type_choices=[253, 166], correct_first_node_type_choices_batch=[253], correct_first_node_type_choices_ptr=[254], sa_score=[253], clogp=[253], mol_weight=[253], qed=[253], bertz=[253], l1000_idx=[253], original_graph_edge_index=[2, 14754], original_graph_x=[6757, 59], original_graph_x_batch=[6757], original_graph_x_ptr=[254], valid_attachment_point_choices=[53], valid_attachment_point_choices_batch=[53], valid_attachment_point_choices_ptr=[254], batch=[3796], ptr=[254], gene_expressions=[253, 978], dose=[253])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[791]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "506149eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can we remove this data point?\n",
    "mask = np.ones(len(train_dataset), dtype=bool)\n",
    "mask[791] = False\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc1149c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LincsDataset(793)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train_dataset[mask]\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f6ff31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4983b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        # sampler=train_sampler,\n",
    "        follow_batch=[\n",
    "            \"correct_edge_choices\",\n",
    "            \"correct_edge_types\",\n",
    "            \"valid_edge_choices\",\n",
    "            \"valid_attachment_point_choices\",\n",
    "            \"correct_attachment_point_choice\",\n",
    "            \"correct_node_type_choices\",\n",
    "            \"original_graph_x\",\n",
    "            \"correct_first_node_type_choices\",\n",
    "        ],\n",
    "        num_workers=NUM_WORKERS,\n",
    "        # prefetch_factor=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c6ca5de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([472])\n",
      "torch.Size([493])\n",
      "torch.Size([504])\n",
      "torch.Size([512])\n",
      "torch.Size([499])\n",
      "torch.Size([495])\n",
      "torch.Size([481])\n",
      "torch.Size([509])\n",
      "torch.Size([465])\n",
      "torch.Size([492])\n",
      "torch.Size([499])\n",
      "torch.Size([499])\n",
      "torch.Size([529])\n",
      "torch.Size([500])\n",
      "torch.Size([517])\n",
      "torch.Size([508])\n",
      "torch.Size([496])\n",
      "torch.Size([502])\n",
      "torch.Size([477])\n",
      "torch.Size([524])\n",
      "torch.Size([499])\n",
      "torch.Size([521])\n",
      "torch.Size([486])\n",
      "torch.Size([530])\n",
      "torch.Size([502])\n",
      "torch.Size([485])\n",
      "torch.Size([485])\n",
      "torch.Size([517])\n",
      "torch.Size([499])\n",
      "torch.Size([507])\n",
      "torch.Size([466])\n",
      "torch.Size([499])\n",
      "torch.Size([506])\n",
      "torch.Size([484])\n",
      "torch.Size([487])\n",
      "torch.Size([495])\n",
      "torch.Size([519])\n",
      "torch.Size([527])\n",
      "torch.Size([471])\n",
      "torch.Size([483])\n",
      "torch.Size([502])\n",
      "torch.Size([478])\n",
      "torch.Size([516])\n",
      "torch.Size([492])\n",
      "torch.Size([478])\n",
      "torch.Size([482])\n",
      "torch.Size([509])\n",
      "torch.Size([503])\n",
      "torch.Size([507])\n",
      "torch.Size([483])\n",
      "torch.Size([495])\n",
      "torch.Size([532])\n",
      "torch.Size([488])\n",
      "torch.Size([495])\n",
      "torch.Size([479])\n",
      "torch.Size([486])\n",
      "torch.Size([514])\n",
      "torch.Size([499])\n",
      "torch.Size([475])\n",
      "torch.Size([515])\n",
      "torch.Size([528])\n",
      "torch.Size([503])\n",
      "torch.Size([499])\n",
      "torch.Size([493])\n",
      "torch.Size([479])\n",
      "torch.Size([509])\n",
      "torch.Size([518])\n",
      "torch.Size([515])\n",
      "torch.Size([484])\n",
      "torch.Size([511])\n",
      "torch.Size([493])\n",
      "torch.Size([483])\n",
      "torch.Size([486])\n",
      "torch.Size([527])\n",
      "torch.Size([494])\n",
      "torch.Size([527])\n",
      "torch.Size([497])\n",
      "torch.Size([505])\n",
      "torch.Size([481])\n",
      "torch.Size([494])\n",
      "torch.Size([496])\n",
      "torch.Size([495])\n",
      "torch.Size([505])\n",
      "torch.Size([510])\n",
      "torch.Size([524])\n",
      "torch.Size([501])\n",
      "torch.Size([491])\n",
      "torch.Size([515])\n",
      "torch.Size([502])\n",
      "torch.Size([496])\n",
      "torch.Size([491])\n",
      "torch.Size([515])\n",
      "torch.Size([512])\n",
      "torch.Size([500])\n",
      "torch.Size([483])\n",
      "torch.Size([516])\n",
      "torch.Size([477])\n",
      "torch.Size([497])\n",
      "torch.Size([522])\n",
      "torch.Size([490])\n",
      "torch.Size([503])\n",
      "torch.Size([495])\n",
      "torch.Size([492])\n",
      "torch.Size([501])\n",
      "torch.Size([503])\n",
      "torch.Size([521])\n",
      "torch.Size([501])\n",
      "torch.Size([493])\n",
      "torch.Size([489])\n",
      "torch.Size([485])\n",
      "torch.Size([508])\n",
      "torch.Size([485])\n",
      "torch.Size([527])\n",
      "torch.Size([509])\n",
      "torch.Size([502])\n",
      "torch.Size([510])\n",
      "torch.Size([493])\n",
      "torch.Size([528])\n",
      "torch.Size([507])\n",
      "torch.Size([514])\n",
      "torch.Size([499])\n",
      "torch.Size([546])\n",
      "torch.Size([523])\n",
      "torch.Size([481])\n",
      "torch.Size([501])\n",
      "torch.Size([505])\n",
      "torch.Size([493])\n",
      "torch.Size([486])\n",
      "torch.Size([500])\n",
      "torch.Size([505])\n",
      "torch.Size([478])\n",
      "torch.Size([485])\n",
      "torch.Size([508])\n",
      "torch.Size([488])\n",
      "torch.Size([511])\n",
      "torch.Size([488])\n",
      "torch.Size([507])\n",
      "torch.Size([487])\n",
      "torch.Size([477])\n",
      "torch.Size([498])\n",
      "torch.Size([496])\n",
      "torch.Size([482])\n",
      "torch.Size([522])\n",
      "torch.Size([497])\n",
      "torch.Size([508])\n",
      "torch.Size([507])\n",
      "torch.Size([469])\n",
      "torch.Size([490])\n",
      "torch.Size([483])\n",
      "torch.Size([483])\n",
      "torch.Size([522])\n",
      "torch.Size([499])\n",
      "torch.Size([469])\n",
      "torch.Size([490])\n",
      "torch.Size([514])\n",
      "torch.Size([480])\n",
      "torch.Size([505])\n",
      "torch.Size([501])\n",
      "torch.Size([494])\n",
      "torch.Size([504])\n",
      "torch.Size([489])\n",
      "torch.Size([501])\n",
      "torch.Size([502])\n",
      "torch.Size([511])\n",
      "torch.Size([481])\n",
      "torch.Size([522])\n",
      "torch.Size([508])\n",
      "torch.Size([500])\n",
      "torch.Size([497])\n",
      "torch.Size([487])\n",
      "torch.Size([486])\n",
      "torch.Size([497])\n",
      "torch.Size([507])\n",
      "torch.Size([538])\n",
      "torch.Size([475])\n",
      "torch.Size([493])\n",
      "torch.Size([518])\n",
      "torch.Size([485])\n",
      "torch.Size([506])\n",
      "torch.Size([512])\n",
      "torch.Size([494])\n",
      "torch.Size([479])\n",
      "torch.Size([500])\n",
      "torch.Size([516])\n",
      "torch.Size([523])\n",
      "torch.Size([510])\n",
      "torch.Size([512])\n",
      "torch.Size([491])\n",
      "torch.Size([514])\n",
      "torch.Size([507])\n",
      "torch.Size([515])\n",
      "torch.Size([507])\n",
      "torch.Size([498])\n",
      "torch.Size([520])\n",
      "torch.Size([491])\n",
      "torch.Size([517])\n",
      "torch.Size([510])\n",
      "torch.Size([503])\n",
      "torch.Size([478])\n",
      "torch.Size([489])\n",
      "torch.Size([488])\n",
      "torch.Size([492])\n",
      "torch.Size([485])\n",
      "torch.Size([496])\n",
      "torch.Size([496])\n",
      "torch.Size([509])\n",
      "torch.Size([511])\n",
      "torch.Size([489])\n",
      "torch.Size([495])\n",
      "torch.Size([526])\n",
      "torch.Size([514])\n",
      "torch.Size([479])\n",
      "torch.Size([496])\n",
      "torch.Size([511])\n",
      "torch.Size([485])\n",
      "torch.Size([484])\n",
      "torch.Size([492])\n",
      "torch.Size([505])\n",
      "torch.Size([494])\n",
      "torch.Size([502])\n",
      "torch.Size([498])\n",
      "torch.Size([490])\n",
      "torch.Size([511])\n",
      "torch.Size([514])\n",
      "torch.Size([506])\n",
      "torch.Size([499])\n",
      "torch.Size([505])\n",
      "torch.Size([496])\n",
      "torch.Size([525])\n",
      "torch.Size([517])\n",
      "torch.Size([489])\n",
      "torch.Size([507])\n",
      "torch.Size([493])\n",
      "torch.Size([491])\n",
      "torch.Size([508])\n",
      "torch.Size([500])\n",
      "torch.Size([538])\n",
      "torch.Size([511])\n",
      "torch.Size([494])\n",
      "torch.Size([472])\n",
      "torch.Size([502])\n",
      "torch.Size([473])\n",
      "torch.Size([529])\n",
      "torch.Size([490])\n",
      "torch.Size([534])\n",
      "torch.Size([479])\n",
      "torch.Size([521])\n",
      "torch.Size([483])\n",
      "torch.Size([520])\n",
      "torch.Size([505])\n",
      "torch.Size([507])\n",
      "torch.Size([526])\n",
      "torch.Size([509])\n",
      "torch.Size([514])\n",
      "torch.Size([519])\n",
      "torch.Size([489])\n",
      "torch.Size([529])\n",
      "torch.Size([527])\n",
      "torch.Size([510])\n",
      "torch.Size([509])\n",
      "torch.Size([491])\n",
      "torch.Size([460])\n",
      "torch.Size([486])\n",
      "torch.Size([497])\n",
      "torch.Size([494])\n",
      "torch.Size([510])\n",
      "torch.Size([498])\n",
      "torch.Size([499])\n",
      "torch.Size([517])\n",
      "torch.Size([509])\n",
      "torch.Size([492])\n",
      "torch.Size([516])\n",
      "torch.Size([527])\n",
      "torch.Size([479])\n",
      "torch.Size([492])\n",
      "torch.Size([485])\n",
      "torch.Size([534])\n",
      "torch.Size([492])\n",
      "torch.Size([485])\n",
      "torch.Size([484])\n",
      "torch.Size([510])\n",
      "torch.Size([498])\n",
      "torch.Size([473])\n",
      "torch.Size([532])\n",
      "torch.Size([503])\n",
      "torch.Size([529])\n",
      "torch.Size([506])\n",
      "torch.Size([494])\n",
      "torch.Size([530])\n",
      "torch.Size([517])\n",
      "torch.Size([509])\n",
      "torch.Size([494])\n",
      "torch.Size([487])\n",
      "torch.Size([495])\n",
      "torch.Size([494])\n",
      "torch.Size([486])\n",
      "torch.Size([505])\n",
      "torch.Size([499])\n",
      "torch.Size([497])\n",
      "torch.Size([499])\n",
      "torch.Size([483])\n",
      "torch.Size([505])\n",
      "torch.Size([493])\n",
      "torch.Size([517])\n",
      "torch.Size([516])\n",
      "torch.Size([490])\n",
      "torch.Size([508])\n",
      "torch.Size([532])\n",
      "torch.Size([484])\n",
      "torch.Size([481])\n",
      "torch.Size([509])\n",
      "torch.Size([510])\n",
      "torch.Size([521])\n",
      "torch.Size([468])\n",
      "torch.Size([506])\n",
      "torch.Size([487])\n",
      "torch.Size([520])\n",
      "torch.Size([520])\n",
      "torch.Size([502])\n",
      "torch.Size([510])\n",
      "torch.Size([463])\n",
      "torch.Size([475])\n",
      "torch.Size([506])\n",
      "torch.Size([497])\n",
      "torch.Size([481])\n",
      "torch.Size([513])\n",
      "torch.Size([494])\n",
      "torch.Size([485])\n",
      "torch.Size([504])\n",
      "torch.Size([545])\n",
      "torch.Size([491])\n",
      "torch.Size([507])\n",
      "torch.Size([496])\n",
      "torch.Size([508])\n",
      "torch.Size([489])\n",
      "torch.Size([507])\n",
      "torch.Size([508])\n",
      "torch.Size([492])\n",
      "torch.Size([517])\n",
      "torch.Size([531])\n",
      "torch.Size([515])\n",
      "torch.Size([494])\n",
      "torch.Size([506])\n",
      "torch.Size([488])\n",
      "torch.Size([493])\n",
      "torch.Size([560])\n",
      "torch.Size([493])\n",
      "torch.Size([513])\n",
      "torch.Size([498])\n",
      "torch.Size([495])\n",
      "torch.Size([501])\n",
      "torch.Size([510])\n",
      "torch.Size([481])\n",
      "torch.Size([526])\n",
      "torch.Size([526])\n",
      "torch.Size([502])\n",
      "torch.Size([507])\n",
      "torch.Size([495])\n",
      "torch.Size([519])\n",
      "torch.Size([491])\n",
      "torch.Size([476])\n",
      "torch.Size([521])\n",
      "torch.Size([489])\n",
      "torch.Size([491])\n",
      "torch.Size([517])\n",
      "torch.Size([514])\n",
      "torch.Size([485])\n",
      "torch.Size([486])\n",
      "torch.Size([471])\n",
      "torch.Size([519])\n",
      "torch.Size([497])\n",
      "torch.Size([498])\n",
      "torch.Size([503])\n",
      "torch.Size([475])\n",
      "torch.Size([504])\n",
      "torch.Size([511])\n",
      "torch.Size([509])\n",
      "torch.Size([493])\n",
      "torch.Size([471])\n",
      "torch.Size([484])\n",
      "torch.Size([515])\n",
      "torch.Size([506])\n",
      "torch.Size([476])\n",
      "torch.Size([479])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([504])\n",
      "torch.Size([504])\n",
      "torch.Size([496])\n",
      "torch.Size([506])\n",
      "torch.Size([513])\n",
      "torch.Size([497])\n",
      "torch.Size([504])\n",
      "torch.Size([502])\n",
      "torch.Size([486])\n",
      "torch.Size([499])\n",
      "torch.Size([498])\n",
      "torch.Size([503])\n",
      "torch.Size([487])\n",
      "torch.Size([491])\n",
      "torch.Size([513])\n",
      "torch.Size([513])\n",
      "torch.Size([498])\n",
      "torch.Size([498])\n",
      "torch.Size([505])\n",
      "torch.Size([513])\n",
      "torch.Size([512])\n",
      "torch.Size([490])\n",
      "torch.Size([468])\n",
      "torch.Size([502])\n",
      "torch.Size([468])\n",
      "torch.Size([484])\n",
      "torch.Size([504])\n",
      "torch.Size([487])\n",
      "torch.Size([488])\n",
      "torch.Size([501])\n",
      "torch.Size([490])\n",
      "torch.Size([487])\n",
      "torch.Size([514])\n",
      "torch.Size([476])\n",
      "torch.Size([495])\n",
      "torch.Size([497])\n",
      "torch.Size([492])\n",
      "torch.Size([485])\n",
      "torch.Size([514])\n",
      "torch.Size([486])\n",
      "torch.Size([487])\n",
      "torch.Size([482])\n",
      "torch.Size([479])\n",
      "torch.Size([499])\n",
      "torch.Size([513])\n",
      "torch.Size([526])\n",
      "torch.Size([515])\n",
      "torch.Size([481])\n",
      "torch.Size([487])\n",
      "torch.Size([501])\n",
      "torch.Size([525])\n",
      "torch.Size([490])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([491])\n",
      "torch.Size([483])\n",
      "torch.Size([517])\n",
      "torch.Size([509])\n",
      "torch.Size([489])\n",
      "torch.Size([482])\n",
      "torch.Size([487])\n",
      "torch.Size([487])\n",
      "torch.Size([498])\n",
      "torch.Size([487])\n",
      "torch.Size([510])\n",
      "torch.Size([510])\n",
      "torch.Size([504])\n",
      "torch.Size([521])\n",
      "torch.Size([504])\n",
      "torch.Size([519])\n",
      "torch.Size([526])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([498])\n",
      "torch.Size([486])\n",
      "torch.Size([518])\n",
      "torch.Size([517])\n",
      "torch.Size([513])\n",
      "torch.Size([501])\n",
      "torch.Size([514])\n",
      "torch.Size([496])\n",
      "torch.Size([491])\n",
      "torch.Size([503])\n",
      "torch.Size([516])\n",
      "torch.Size([515])\n",
      "torch.Size([500])\n",
      "torch.Size([516])\n",
      "torch.Size([484])\n",
      "torch.Size([482])\n",
      "torch.Size([536])\n",
      "torch.Size([491])\n",
      "torch.Size([495])\n",
      "torch.Size([510])\n",
      "torch.Size([492])\n",
      "torch.Size([497])\n",
      "torch.Size([498])\n",
      "torch.Size([494])\n",
      "torch.Size([506])\n",
      "torch.Size([506])\n",
      "torch.Size([495])\n",
      "torch.Size([511])\n",
      "torch.Size([529])\n",
      "torch.Size([483])\n",
      "torch.Size([483])\n",
      "torch.Size([501])\n",
      "torch.Size([496])\n",
      "torch.Size([496])\n",
      "torch.Size([534])\n",
      "torch.Size([503])\n",
      "torch.Size([506])\n",
      "torch.Size([529])\n",
      "torch.Size([486])\n",
      "torch.Size([516])\n",
      "torch.Size([479])\n",
      "torch.Size([508])\n",
      "torch.Size([492])\n",
      "torch.Size([522])\n",
      "torch.Size([533])\n",
      "torch.Size([504])\n",
      "torch.Size([511])\n",
      "torch.Size([484])\n",
      "torch.Size([496])\n",
      "torch.Size([509])\n",
      "torch.Size([460])\n",
      "torch.Size([493])\n",
      "torch.Size([487])\n",
      "torch.Size([522])\n",
      "torch.Size([491])\n",
      "torch.Size([499])\n",
      "torch.Size([504])\n",
      "torch.Size([493])\n",
      "torch.Size([468])\n",
      "torch.Size([492])\n",
      "torch.Size([498])\n",
      "torch.Size([499])\n",
      "torch.Size([509])\n",
      "torch.Size([506])\n",
      "torch.Size([469])\n",
      "torch.Size([480])\n",
      "torch.Size([510])\n",
      "torch.Size([496])\n",
      "torch.Size([512])\n",
      "torch.Size([517])\n",
      "torch.Size([514])\n",
      "torch.Size([512])\n",
      "torch.Size([514])\n",
      "torch.Size([520])\n",
      "torch.Size([504])\n",
      "torch.Size([480])\n",
      "torch.Size([503])\n",
      "torch.Size([491])\n",
      "torch.Size([466])\n",
      "torch.Size([520])\n",
      "torch.Size([497])\n",
      "torch.Size([496])\n",
      "torch.Size([503])\n",
      "torch.Size([503])\n",
      "torch.Size([491])\n",
      "torch.Size([500])\n",
      "torch.Size([504])\n",
      "torch.Size([477])\n",
      "torch.Size([513])\n",
      "torch.Size([519])\n",
      "torch.Size([483])\n",
      "torch.Size([494])\n",
      "torch.Size([491])\n",
      "torch.Size([499])\n",
      "torch.Size([495])\n",
      "torch.Size([453])\n",
      "torch.Size([536])\n",
      "torch.Size([479])\n",
      "torch.Size([505])\n",
      "torch.Size([501])\n",
      "torch.Size([483])\n",
      "torch.Size([513])\n",
      "torch.Size([511])\n",
      "torch.Size([506])\n",
      "torch.Size([506])\n",
      "torch.Size([509])\n",
      "torch.Size([516])\n",
      "torch.Size([491])\n",
      "torch.Size([507])\n",
      "torch.Size([475])\n",
      "torch.Size([476])\n",
      "torch.Size([494])\n",
      "torch.Size([497])\n",
      "torch.Size([508])\n",
      "torch.Size([510])\n",
      "torch.Size([475])\n",
      "torch.Size([476])\n",
      "torch.Size([495])\n",
      "torch.Size([528])\n",
      "torch.Size([510])\n",
      "torch.Size([509])\n",
      "torch.Size([490])\n",
      "torch.Size([474])\n",
      "torch.Size([465])\n",
      "torch.Size([516])\n",
      "torch.Size([484])\n",
      "torch.Size([503])\n",
      "torch.Size([469])\n",
      "torch.Size([516])\n",
      "torch.Size([507])\n",
      "torch.Size([492])\n",
      "torch.Size([488])\n",
      "torch.Size([509])\n",
      "torch.Size([501])\n",
      "torch.Size([521])\n",
      "torch.Size([481])\n",
      "torch.Size([500])\n",
      "torch.Size([490])\n",
      "torch.Size([482])\n",
      "torch.Size([512])\n",
      "torch.Size([522])\n",
      "torch.Size([516])\n",
      "torch.Size([523])\n",
      "torch.Size([502])\n",
      "torch.Size([510])\n",
      "torch.Size([490])\n",
      "torch.Size([505])\n",
      "torch.Size([526])\n",
      "torch.Size([489])\n",
      "torch.Size([491])\n",
      "torch.Size([520])\n",
      "torch.Size([520])\n",
      "torch.Size([492])\n",
      "torch.Size([478])\n",
      "torch.Size([502])\n",
      "torch.Size([492])\n",
      "torch.Size([512])\n",
      "torch.Size([467])\n",
      "torch.Size([473])\n",
      "torch.Size([477])\n",
      "torch.Size([491])\n",
      "torch.Size([501])\n",
      "torch.Size([480])\n",
      "torch.Size([502])\n",
      "torch.Size([507])\n",
      "torch.Size([490])\n",
      "torch.Size([505])\n",
      "torch.Size([510])\n",
      "torch.Size([506])\n",
      "torch.Size([485])\n",
      "torch.Size([489])\n",
      "torch.Size([493])\n",
      "torch.Size([526])\n",
      "torch.Size([498])\n",
      "torch.Size([479])\n",
      "torch.Size([468])\n",
      "torch.Size([513])\n",
      "torch.Size([496])\n",
      "torch.Size([498])\n",
      "torch.Size([503])\n",
      "torch.Size([520])\n",
      "torch.Size([496])\n",
      "torch.Size([480])\n",
      "torch.Size([490])\n",
      "torch.Size([511])\n",
      "torch.Size([498])\n",
      "torch.Size([498])\n",
      "torch.Size([477])\n",
      "torch.Size([482])\n",
      "torch.Size([502])\n",
      "torch.Size([515])\n",
      "torch.Size([512])\n",
      "torch.Size([499])\n",
      "torch.Size([517])\n",
      "torch.Size([499])\n",
      "torch.Size([482])\n",
      "torch.Size([500])\n",
      "torch.Size([491])\n",
      "torch.Size([508])\n",
      "torch.Size([478])\n",
      "torch.Size([491])\n",
      "torch.Size([490])\n",
      "torch.Size([487])\n",
      "torch.Size([499])\n",
      "torch.Size([487])\n",
      "torch.Size([517])\n",
      "torch.Size([513])\n",
      "torch.Size([493])\n",
      "torch.Size([491])\n",
      "torch.Size([508])\n",
      "torch.Size([491])\n",
      "torch.Size([509])\n",
      "torch.Size([480])\n",
      "torch.Size([523])\n",
      "torch.Size([471])\n",
      "torch.Size([513])\n",
      "torch.Size([505])\n",
      "torch.Size([510])\n",
      "torch.Size([520])\n",
      "torch.Size([484])\n",
      "torch.Size([499])\n",
      "torch.Size([486])\n",
      "torch.Size([505])\n",
      "torch.Size([487])\n",
      "torch.Size([501])\n",
      "torch.Size([538])\n",
      "torch.Size([481])\n",
      "torch.Size([493])\n",
      "torch.Size([497])\n",
      "torch.Size([505])\n",
      "torch.Size([487])\n",
      "torch.Size([524])\n",
      "torch.Size([489])\n",
      "torch.Size([484])\n",
      "torch.Size([460])\n",
      "torch.Size([487])\n",
      "torch.Size([481])\n",
      "torch.Size([537])\n",
      "torch.Size([534])\n",
      "torch.Size([481])\n",
      "torch.Size([491])\n",
      "torch.Size([496])\n",
      "torch.Size([496])\n",
      "torch.Size([480])\n",
      "torch.Size([489])\n",
      "torch.Size([494])\n",
      "torch.Size([501])\n",
      "torch.Size([483])\n",
      "torch.Size([508])\n",
      "torch.Size([489])\n",
      "torch.Size([476])\n",
      "torch.Size([513])\n",
      "torch.Size([516])\n",
      "torch.Size([505])\n",
      "torch.Size([514])\n",
      "torch.Size([494])\n",
      "torch.Size([472])\n",
      "torch.Size([501])\n",
      "torch.Size([496])\n",
      "torch.Size([486])\n",
      "torch.Size([500])\n",
      "torch.Size([500])\n",
      "torch.Size([504])\n",
      "torch.Size([474])\n",
      "torch.Size([510])\n",
      "torch.Size([504])\n",
      "torch.Size([488])\n",
      "torch.Size([526])\n",
      "torch.Size([490])\n",
      "torch.Size([477])\n",
      "torch.Size([514])\n",
      "torch.Size([470])\n",
      "torch.Size([502])\n",
      "torch.Size([487])\n",
      "torch.Size([474])\n",
      "torch.Size([516])\n",
      "torch.Size([501])\n",
      "torch.Size([492])\n",
      "torch.Size([477])\n",
      "torch.Size([504])\n",
      "torch.Size([474])\n",
      "torch.Size([487])\n",
      "torch.Size([504])\n",
      "torch.Size([496])\n",
      "torch.Size([510])\n",
      "torch.Size([501])\n",
      "torch.Size([549])\n",
      "torch.Size([504])\n",
      "torch.Size([468])\n",
      "torch.Size([499])\n",
      "torch.Size([513])\n",
      "torch.Size([513])\n",
      "torch.Size([498])\n",
      "torch.Size([483])\n",
      "torch.Size([488])\n",
      "torch.Size([478])\n",
      "torch.Size([538])\n",
      "torch.Size([516])\n",
      "torch.Size([522])\n",
      "torch.Size([494])\n",
      "torch.Size([516])\n",
      "torch.Size([517])\n",
      "torch.Size([468])\n",
      "torch.Size([471])\n",
      "torch.Size([483])\n",
      "torch.Size([509])\n",
      "torch.Size([512])\n",
      "torch.Size([490])\n",
      "torch.Size([496])\n",
      "torch.Size([484])\n",
      "torch.Size([480])\n",
      "torch.Size([529])\n",
      "torch.Size([497])\n",
      "torch.Size([486])\n",
      "torch.Size([513])\n",
      "torch.Size([485])\n",
      "torch.Size([514])\n",
      "torch.Size([525])\n",
      "torch.Size([514])\n",
      "torch.Size([515])\n",
      "torch.Size([516])\n",
      "torch.Size([516])\n",
      "torch.Size([500])\n",
      "torch.Size([473])\n",
      "torch.Size([526])\n",
      "torch.Size([490])\n",
      "torch.Size([476])\n",
      "torch.Size([494])\n",
      "torch.Size([484])\n",
      "torch.Size([517])\n",
      "torch.Size([515])\n",
      "torch.Size([470])\n",
      "torch.Size([503])\n",
      "torch.Size([518])\n",
      "torch.Size([259])\n",
      "torch.Size([503])\n",
      "torch.Size([492])\n"
     ]
    }
   ],
   "source": [
    "for id, batch in enumerate(train_dataloader):\n",
    "    if batch.dose.size(0) == 1000:\n",
    "        print(id)\n",
    "    else:\n",
    "        print(batch.dose.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eccad3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading controls gene expression...\n",
      "Loading tumour gene expression...\n",
      "Loading csv...\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = LincsDataset(\n",
    "    root=\"/data/ongh0068\",\n",
    "    raw_moler_trace_dataset_parent_folder=raw_moler_trace_dataset_parent_folder,  # \"/data/ongh0068/l1000/trace_playground\",\n",
    "    output_pyg_trace_dataset_parent_folder=output_pyg_trace_dataset_parent_folder,\n",
    "    gene_exp_controls_file_path=\"/data/ongh0068/l1000/lincs/robust_normalized_controls.npz\",\n",
    "    gene_exp_tumour_file_path=\"/data/ongh0068/l1000/lincs/robust_normalized_tumors.npz\",\n",
    "    lincs_csv_file_path=\"/data/ongh0068/l1000/lincs/experiments_filtered.csv\",\n",
    "    split=valid_split,\n",
    "    gen_step_drop_probability=gen_step_drop_probability,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3aca0782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the same mask to filter val dataset\n",
    "valid_dataset = valid_dataset[mask]\n",
    "len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f3e63c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        # sampler=valid_sampler,\n",
    "        follow_batch=[\n",
    "            \"correct_edge_choices\",\n",
    "            \"correct_edge_types\",\n",
    "            \"valid_edge_choices\",\n",
    "            \"valid_attachment_point_choices\",\n",
    "            \"correct_attachment_point_choice\",\n",
    "            \"correct_node_type_choices\",\n",
    "            \"original_graph_x\",\n",
    "            \"correct_first_node_type_choices\",\n",
    "        ],\n",
    "        num_workers=NUM_WORKERS,\n",
    "        # prefetch_factor=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7df7f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "torch.Size([520])\n",
      "792\n",
      "793\n"
     ]
    }
   ],
   "source": [
    "for id, batch in enumerate(valid_dataloader):\n",
    "    if batch.dose.size(0) == 1000:\n",
    "        print(id)\n",
    "    else:\n",
    "        print(batch.dose.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a0e6c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_id, batch in enumerate(valid_dataloader):\n",
    "    if batch['dose'].size(0) == 1000:\n",
    "        \n",
    "        continue\n",
    "    else:\n",
    "        print(batch_id)\n",
    "        print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c4aef2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_graph_encoder': {'input_feature_dim': 59,\n",
       "  'atom_or_motif_vocab_size': 166,\n",
       "  'aggr_layer_type': 'MoLeRAggregation',\n",
       "  'total_num_moler_aggr_heads': 32,\n",
       "  'layer_type': 'FiLMConv'},\n",
       " 'partial_graph_encoder': {'input_feature_dim': 59,\n",
       "  'atom_or_motif_vocab_size': 166,\n",
       "  'aggr_layer_type': 'MoLeRAggregation',\n",
       "  'total_num_moler_aggr_heads': 16,\n",
       "  'layer_type': 'FiLMConv'},\n",
       " 'mean_log_var_mlp': {'input_feature_dim': 832,\n",
       "  'output_size': 1024,\n",
       "  'hidden_layer_dims': [],\n",
       "  'use_bias': False},\n",
       " 'decoder': {'node_type_selector': {'input_feature_dim': 1344,\n",
       "   'output_size': 167},\n",
       "  'use_node_type_loss_weights': True,\n",
       "  'node_type_loss_weights': tensor([10.0000,  0.1000,  3.6015,  0.1000,  0.1000,  0.4439,  0.7549,  0.4416,\n",
       "          10.0000,  2.7939,  3.3916, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
       "          10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,  0.1731]),\n",
       "  'no_more_edges_repr': (1, 835),\n",
       "  'edge_candidate_scorer': {'input_feature_dim': 3011,\n",
       "   'output_size': 1,\n",
       "   'hidden_layer_dims': [128, 64, 32],\n",
       "   'dropout_prob': 0.0},\n",
       "  'edge_type_selector': {'input_feature_dim': 3011,\n",
       "   'output_size': 3,\n",
       "   'hidden_layer_dims': [128, 64, 32],\n",
       "   'dropout_prob': 0.0},\n",
       "  'attachment_point_selector': {'input_feature_dim': 2176,\n",
       "   'output_size': 1,\n",
       "   'hidden_layer_dims': [128, 64, 32],\n",
       "   'dropout_prob': 0.0},\n",
       "  'first_node_type_selector': {'input_feature_dim': 512,\n",
       "   'output_size': 166,\n",
       "   'hidden_layer_dims': [256, 256],\n",
       "   'dropout_prob': 0.0}},\n",
       " 'graph_properties': {'sa_score': {'type': 'regression',\n",
       "   'normalise_loss': True,\n",
       "   'mlp': {'input_feature_dim': 512,\n",
       "    'output_size': 1,\n",
       "    'hidden_layer_dims': [64, 32],\n",
       "    'dropout_prob': 0.0,\n",
       "    'loss_weight_factor': 0.33}},\n",
       "  'clogp': {'type': 'regression',\n",
       "   'normalise_loss': True,\n",
       "   'mlp': {'input_feature_dim': 512,\n",
       "    'output_size': 1,\n",
       "    'hidden_layer_dims': [64, 32],\n",
       "    'dropout_prob': 0.0,\n",
       "    'loss_weight_factor': 0.33}},\n",
       "  'mol_weight': {'type': 'regression',\n",
       "   'normalise_loss': True,\n",
       "   'mlp': {'input_feature_dim': 512,\n",
       "    'output_size': 1,\n",
       "    'hidden_layer_dims': [64, 32],\n",
       "    'dropout_prob': 0.0,\n",
       "    'loss_weight_factor': 0.33}}},\n",
       " 'graph_property_pred_loss_weight': 0.1,\n",
       " 'latent_sample_strategy': 'per_graph',\n",
       " 'latent_repr_dim': 512,\n",
       " 'latent_repr_size': 512,\n",
       " 'kl_divergence_weight': 0.02,\n",
       " 'kl_divergence_annealing_beta': 0.999,\n",
       " 'training_hyperparams': {'max_lr': 0.0001,\n",
       "  'div_factor': 10,\n",
       "  'three_phase': True},\n",
       " 'use_oclr_scheduler': False,\n",
       " 'decode_on_validation_end': True,\n",
       " 'using_cyclical_anneal': False,\n",
       " 'discriminator': {'input_feature_dim': 832,\n",
       "  'output_size': 1,\n",
       "  'hidden_layer_dims': [256, 128, 64]},\n",
       " 'latent_repr_mlp': {'input_feature_dim': 832,\n",
       "  'output_size': 512,\n",
       "  'hidden_layer_dims': [],\n",
       "  'use_bias': False},\n",
       " 'gene_exp_condition_mlp': {'input_feature_dim': 1491,\n",
       "  'output_size': 512,\n",
       "  'hidden_layer_dims': [],\n",
       "  'use_bias': False},\n",
       " 'gene_exp_prediction_mlp': {'input_feature_dim': 512,\n",
       "  'output_size': 978,\n",
       "  'hidden_layer_dims': [768],\n",
       "  'dropout_prob': 0.0,\n",
       "  'loss_weight_factor': 0.33}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_stage_params = get_params(train_dataset)\n",
    "first_stage_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04072167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 'model.BaseModel', 'model_type': 'vae', 'using_lincs': True, 'ckpt_path': '/data/conghao001/FYP/DrugDiscovery/first_stage_models/2023-03-11_23_33_36.921147/epoch=07-val_loss=0.60.ckpt'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_stage_config = config['model']['first_stage_config']\n",
    "first_stage_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6e9157c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDiffusion: Running in x0-prediction mode\n",
      "DiffusionWrapper has 1303.74 M params.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDiffusion(\n",
       "  (model): DiffusionWrapper(\n",
       "    (diffusion_model): UNetModel(\n",
       "      (time_embed): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      )\n",
       "      (input_blocks): ModuleList(\n",
       "        (0): TimestepEmbedSequential(\n",
       "          (0): Conv1d(1000, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "        (1): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "        )\n",
       "        (2): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): TimestepEmbedSequential(\n",
       "          (0): Downsample(\n",
       "            (op): Conv1d(1024, 1024, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (4): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv1d(1024, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2048, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (skip_connection): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 2048, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(2048, 6144, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(2048, 2048, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (5): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2048, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2048, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 2048, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(2048, 6144, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(2048, 2048, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (6): TimestepEmbedSequential(\n",
       "          (0): Downsample(\n",
       "            (op): Conv1d(2048, 2048, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (7): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2048, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv1d(2048, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=4096, out_features=3072, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv1d(3072, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (skip_connection): Conv1d(2048, 3072, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(3072, 9216, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(3072, 3072, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (8): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv1d(3072, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=4096, out_features=3072, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv1d(3072, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(3072, 9216, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(3072, 3072, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (middle_block): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv1d(3072, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=4096, out_features=3072, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv1d(3072, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(3072, 9216, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttentionLegacy()\n",
       "          (proj_out): Conv1d(3072, 3072, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv1d(3072, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=4096, out_features=3072, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv1d(3072, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (output_blocks): ModuleList(\n",
       "        (0): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 6144, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv1d(6144, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=4096, out_features=3072, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv1d(3072, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (skip_connection): Conv1d(6144, 3072, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(3072, 9216, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(3072, 3072, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (1): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 6144, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv1d(6144, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=4096, out_features=3072, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv1d(3072, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (skip_connection): Conv1d(6144, 3072, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(3072, 9216, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(3072, 3072, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (2): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv1d(5120, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=4096, out_features=3072, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv1d(3072, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (skip_connection): Conv1d(5120, 3072, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(3072, 9216, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(3072, 3072, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): Upsample(\n",
       "            (conv): Conv1d(3072, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (3): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 5120, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv1d(5120, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2048, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (skip_connection): Conv1d(5120, 2048, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 2048, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(2048, 6144, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(2048, 2048, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (4): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 4096, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv1d(4096, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2048, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (skip_connection): Conv1d(4096, 2048, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 2048, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(2048, 6144, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(2048, 2048, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (5): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv1d(3072, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2048, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (skip_connection): Conv1d(3072, 2048, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 2048, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(2048, 6144, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(2048, 2048, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): Upsample(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (6): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 3072, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv1d(3072, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (skip_connection): Conv1d(3072, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (7): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2048, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv1d(2048, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (skip_connection): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (8): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2048, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv1d(2048, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (skip_connection): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (out): Sequential(\n",
       "        (0): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv1d(1024, 1000, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (first_stage_model): BaseModel(\n",
       "    (_full_graph_encoder): GraphEncoder(\n",
       "      (_embed): Embedding(166, 64)\n",
       "      (_model): GenericGraphEncoder(\n",
       "        (_first_layer): FiLMConv(123, 64, num_relations=3)\n",
       "        (_encoder_layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (6): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (7): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (8): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (9): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (10): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (11): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "        )\n",
       "        (_softmax_aggr): WeightedSumGraphRepresentation(\n",
       "          (_transformation_mlp_activation_fun): LeakyReLU(negative_slope=0.01)\n",
       "          (_scoring_mlp): GenericMLP(\n",
       "            (_hidden_layers): ModuleList(\n",
       "              (0): Linear(in_features=832, out_features=128, bias=True)\n",
       "              (1): LeakyReLU(negative_slope=0.01)\n",
       "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "            (_final_layer): Linear(in_features=128, out_features=16, bias=True)\n",
       "          )\n",
       "          (_transformation_mlp): GenericMLP(\n",
       "            (_hidden_layers): ModuleList(\n",
       "              (0): Linear(in_features=832, out_features=128, bias=True)\n",
       "              (1): LeakyReLU(negative_slope=0.01)\n",
       "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "            (_final_layer): Linear(in_features=128, out_features=416, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_sigmoid_aggr): WeightedSumGraphRepresentation(\n",
       "          (_transformation_mlp_activation_fun): LeakyReLU(negative_slope=0.01)\n",
       "          (_scoring_mlp): GenericMLP(\n",
       "            (_hidden_layers): ModuleList(\n",
       "              (0): Linear(in_features=832, out_features=128, bias=True)\n",
       "              (1): LeakyReLU(negative_slope=0.01)\n",
       "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "            (_final_layer): Linear(in_features=128, out_features=16, bias=True)\n",
       "          )\n",
       "          (_transformation_mlp): GenericMLP(\n",
       "            (_hidden_layers): ModuleList(\n",
       "              (0): Linear(in_features=832, out_features=128, bias=True)\n",
       "              (1): LeakyReLU(negative_slope=0.01)\n",
       "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "            (_final_layer): Linear(in_features=128, out_features=416, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (_partial_graph_encoder): PartialGraphEncoder(\n",
       "      (_embed): Embedding(166, 64)\n",
       "      (_model): GenericGraphEncoder(\n",
       "        (_first_layer): FiLMConv(124, 64, num_relations=3)\n",
       "        (_encoder_layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (6): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (7): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (8): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (9): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (10): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "          (11): Sequential(\n",
       "            (0): LayerNorm(64, mode=graph)\n",
       "            (1): FiLMConv(64, 64, num_relations=3)\n",
       "          )\n",
       "        )\n",
       "        (_softmax_aggr): WeightedSumGraphRepresentation(\n",
       "          (_transformation_mlp_activation_fun): LeakyReLU(negative_slope=0.01)\n",
       "          (_scoring_mlp): GenericMLP(\n",
       "            (_hidden_layers): ModuleList(\n",
       "              (0): Linear(in_features=832, out_features=128, bias=True)\n",
       "              (1): LeakyReLU(negative_slope=0.01)\n",
       "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "            (_final_layer): Linear(in_features=128, out_features=8, bias=True)\n",
       "          )\n",
       "          (_transformation_mlp): GenericMLP(\n",
       "            (_hidden_layers): ModuleList(\n",
       "              (0): Linear(in_features=832, out_features=128, bias=True)\n",
       "              (1): LeakyReLU(negative_slope=0.01)\n",
       "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "            (_final_layer): Linear(in_features=128, out_features=416, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_sigmoid_aggr): WeightedSumGraphRepresentation(\n",
       "          (_transformation_mlp_activation_fun): LeakyReLU(negative_slope=0.01)\n",
       "          (_scoring_mlp): GenericMLP(\n",
       "            (_hidden_layers): ModuleList(\n",
       "              (0): Linear(in_features=832, out_features=128, bias=True)\n",
       "              (1): LeakyReLU(negative_slope=0.01)\n",
       "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "            (_final_layer): Linear(in_features=128, out_features=8, bias=True)\n",
       "          )\n",
       "          (_transformation_mlp): GenericMLP(\n",
       "            (_hidden_layers): ModuleList(\n",
       "              (0): Linear(in_features=832, out_features=128, bias=True)\n",
       "              (1): LeakyReLU(negative_slope=0.01)\n",
       "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "            (_final_layer): Linear(in_features=128, out_features=416, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (_mean_log_var_mlp): GenericMLP(\n",
       "      (_hidden_layers): ModuleList()\n",
       "      (_final_layer): Linear(in_features=832, out_features=1024, bias=False)\n",
       "    )\n",
       "    (_property_predictors): ModuleDict(\n",
       "      (sa_score): PropertyRegressionMLP(\n",
       "        (_mlp): GenericMLP(\n",
       "          (_hidden_layers): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.01)\n",
       "            (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.01)\n",
       "          )\n",
       "          (_final_layer): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (clogp): PropertyRegressionMLP(\n",
       "        (_mlp): GenericMLP(\n",
       "          (_hidden_layers): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.01)\n",
       "            (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.01)\n",
       "          )\n",
       "          (_final_layer): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (mol_weight): PropertyRegressionMLP(\n",
       "        (_mlp): GenericMLP(\n",
       "          (_hidden_layers): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.01)\n",
       "            (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.01)\n",
       "          )\n",
       "          (_final_layer): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (_decoder): MLPDecoder(\n",
       "      (_first_node_type_selector): GenericMLP(\n",
       "        (_hidden_layers): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (_final_layer): Linear(in_features=256, out_features=166, bias=True)\n",
       "      )\n",
       "      (_node_type_selector): GenericMLP(\n",
       "        (_hidden_layers): ModuleList(\n",
       "          (0): Linear(in_features=1344, out_features=256, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (_final_layer): Linear(in_features=256, out_features=167, bias=True)\n",
       "      )\n",
       "      (_edge_candidate_scorer): GenericMLP(\n",
       "        (_hidden_layers): ModuleList(\n",
       "          (0): Linear(in_features=3011, out_features=128, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "          (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "          (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (_final_layer): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "      (_edge_type_selector): GenericMLP(\n",
       "        (_hidden_layers): ModuleList(\n",
       "          (0): Linear(in_features=3011, out_features=128, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "          (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "          (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (_final_layer): Linear(in_features=32, out_features=3, bias=True)\n",
       "      )\n",
       "      (_cross_entropy_loss): CrossEntropyLoss()\n",
       "      (_distance_embedding_layer): Embedding(10, 1)\n",
       "      (_attachment_point_selector): GenericMLP(\n",
       "        (_hidden_layers): ModuleList(\n",
       "          (0): Linear(in_features=2176, out_features=128, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "          (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "          (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (_final_layer): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (_gene_exp_condition_mlp): GenericMLP(\n",
       "      (_hidden_layers): ModuleList()\n",
       "      (_final_layer): Linear(in_features=1491, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldm_model = LatentDiffusion(\n",
    "    first_stage_config,\n",
    "    config['model']['cond_stage_config'],\n",
    "    train_dataset, \n",
    "    batch_size,\n",
    "    first_stage_params,\n",
    "    first_stage_config['ckpt_path'],\n",
    "    unet_config = config['model']['unet_config'],\n",
    "    **ldm_params\n",
    ")\n",
    "ldm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "475f47d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = config.model.base_learning_rate\n",
    "ldm_model.learning_rate = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7de4406b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:1')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db36b8e3",
   "metadata": {},
   "source": [
    "### pytorch lightning config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4df24ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current time for folder path.\n",
    "now = str(datetime.now()).replace(\" \", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "# Callbacks\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "tensorboard_logger = TensorBoardLogger(save_dir=f\"lightning_logs/{now}\", name=f\"logs_{now}\")\n",
    "early_stopping = EarlyStopping(monitor=\"val/loss\", patience=3)\n",
    "if model_architecture == \"vae\":\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        save_top_k=1,\n",
    "        monitor=\"val/loss\",\n",
    "        dirpath=f\"lightning_logs/{now}\",\n",
    "        mode=\"min\",\n",
    "        filename=\"{epoch:02d}-{val_loss:.2f}\",\n",
    "    )\n",
    "elif model_architecture == \"aae\":\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=f\"lightning_logs/{now}\",\n",
    "        filename=\"{epoch:02d}-{train_loss:.2f}\",\n",
    "        monitor=\"epoch\",\n",
    "        every_n_epochs=3,\n",
    "        save_on_train_epoch_end=True,\n",
    "        save_top_k=-1,\n",
    "    )\n",
    "\n",
    "callbacks = (\n",
    "    [checkpoint_callback, lr_monitor, early_stopping]\n",
    "    if model_architecture == \"vae\"\n",
    "    else [checkpoint_callback, lr_monitor]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5dc32ca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: lightning_logs/2023-05-03_18_49_58.215810/logs_2023-05-03_18_49_58.215810\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | model             | DiffusionWrapper | 1.3 B \n",
      "1 | first_stage_model | BaseModel        | 6.1 M \n",
      "-------------------------------------------------------\n",
      "1.3 B     Trainable params\n",
      "6.1 M     Non-trainable params\n",
      "1.3 B     Total params\n",
      "5,239.375 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1a959a94834319841b35009461f1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3faecd56b15b41678ae0e9049c3a48cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conghao001/miniconda3/envs/druggen/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:233: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c612ccf2e9084a1ab76acbf0d133dd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(accelerator='gpu', max_epochs=1, devices=[1], callbacks=callbacks, logger=tensorboard_logger)\n",
    "trainer.fit(ldm_model, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98070a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ldm.modules.diffusionmodules.openaimodel.UNetModel"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import ldm.modules.diffusionmodules.openaimodel\n",
    "from ldm.modules.diffusionmodules.openaimodel import UNetModel\n",
    "from ldm.modules.diffusionmodules.openaimodel import TimestepEmbedSequential\n",
    "\n",
    "string = 'ldm.modules.diffusionmodules.openaimodel.UNetModel'\n",
    "pkg, cls = string.rsplit(\".\", 1)\n",
    "\n",
    "module_imp = importlib.import_module(pkg, package=None)\n",
    "unet_module = getattr(module_imp, cls)\n",
    "unet_module\n",
    "\n",
    "# importlib.import_module('UNetModel')\n",
    "\n",
    "# importlib.reload(unet_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "580bd26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b192c019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drug_gen",
   "language": "python",
   "name": "drug_gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
